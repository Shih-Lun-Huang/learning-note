{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 介紹\n",
    "\n",
    "決策樹解決我們遇到的困難。 一棵有很多葉子的深樹會過度擬合，因為每個預測都來自其葉子上只有少數房屋獨有特徵的歷史數據。 但是，只有很少葉子的淺樹性能會很差，因為它無法捕獲原始數據中盡可能多的差異。\n",
    "\n",
    "即使是當今最複雜的建模技術，也面臨著欠擬合和過度擬合之間的這種張力。但是，許多模型都有巧妙的想法，可以帶來更好的性能。 我們將以 **隨機森林(random forest)** 為例。\n",
    "\n",
    "隨機森林使用許多樹，並且**通過每個組成樹預測的平均來進行預測**。 與單個決策樹相比，它通常具有更好的預測準確性，並且該模型的參數也有不錯的效用。 如果繼續進行建模，則可以學習更多具有更好性能的模型，但是其中許多模型對於獲取正確的參數很敏感。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 舉例\n",
    "\n",
    "您已經看過幾次加載數據的代碼。 在數據加載結束時，我們具有以下變量：\n",
    "\n",
    "- train_X\n",
    "- val_X\n",
    "- train_y\n",
    "- val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "# Load data\n",
    "melbourne_file_path = './data_set/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# Filter rows with missing values\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們類似於在scikit-learn中構建決策樹的方式構建隨機森林模型 - 這次使用 `RandomForestRegressor` 類別而不是 `DecisionTreeRegressor` 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202888.18157951365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "可能還有進一步改進的空間，但是與250,000的最佳決策樹的誤差結果相比，這是一個很大的進步。 當我們更改單個決策樹的最大深度時，可以使用一些參數來更改“隨機森林”的性能。 但是，Random Forest模型的最佳功能之一是，即使不進行此調整參數，它們通常也可以正常工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
