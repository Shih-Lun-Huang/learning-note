{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "282e8ffc",
      "metadata": {
        "papermill": {
          "duration": 0.009232,
          "end_time": "2021-11-09T00:11:07.687942",
          "exception": false,
          "start_time": "2021-11-09T00:11:07.678710",
          "status": "completed"
        },
        "tags": [],
        "id": "282e8ffc"
      },
      "source": [
        "# 介紹\n",
        "\n",
        "到目前為止，在本課程中，我們已經了解了神經網絡如何解決迴歸問題。現在我們要將神經網絡應用於另一個常見的機器學習問題：分類。到目前為止，我們學到的大部分內容仍然適用。主要區別在於我們使用的損失函數以及我們希望最終層產生什麼樣的輸出。\n",
        "\n",
        "# 二進制分類 #\n",
        "\n",
        "分類為兩個類別之一是一個常見的機器學習問題。我們可能想要預測客戶是否可能進行購買、信用卡交易是否具有欺詐性、深空信號是否顯示新行星的證據或疾病的醫學測試證據。這些都是**二元分類**問題。\n",
        "\n",
        "在我們的原始數據中，這些類可能由字符串表示，例如`Yes`和`No`，或`Dog`和`Cat`。在使用這些數據之前，我們將分配一個**類標籤**：一個類是`0`，另一個是`1`。分配數字標籤將數據置於神經網絡可以使用的形式中。\n",
        "\n",
        "# 準確度和交叉熵(Cross-Entropy) #\n",
        "\n",
        "**準確度**是用於衡量分類問題成功的眾多指標之一。準確率是正確預測與總預測的比率：`accuracy = number_correct / total`。完全正確預測的模型的準確度得分為`1.0`。在其他條件相同的情況下，只要數據集中的類別以大致相同的頻率出現，準確性就是一個合理的指標。\n",
        "\n",
        "準確性（以及大多數其他分類指標）的問題在於它**不能用作損失函數**。 SGD 需要一個平滑變化的損失函數，但準確性（作為計數比率）會在“跳躍”中發生變化。因此，我們必須選擇一個替代品作為損失函數。這個替代品是 *cross-entropy* 函數。\n",
        "\n",
        "現在，回想一下損失函數在訓練期間定義了網絡的*目標*。通過迴歸，我們的目標是最小化預期結果和預測結果之間的距離。我們選擇 MAE 來測量這個距離。\n",
        "\n",
        "對於分類，我們想要的是*概率之間的距離*，這就是交叉熵提供的。 **交叉熵**是一種衡量從一個概率分佈到另一個概率分佈的距離。\n",
        "\n",
        "<figure style=\"padding: 1em;\">\n",
        "<img src=\"https://i.imgur.com/DwVV9bR.png\" width=\"400\" alt=\"準確度和交叉熵圖。\">\n",
        "<figcaption style=\"textalign: center; font-style: italic\"><center>交叉熵懲罰不正確的概率預測。</center></figcaption>\n",
        "</figure>\n",
        "\n",
        "這個想法是我們希望我們的網絡以“1.0”的概率預測正確的類別。預測概率離“1.0”越遠，交叉熵損失越大。\n",
        "\n",
        "我們使用交叉熵的技術原因有點微妙，但是從本節中要帶走的主要內容就是：使用交叉熵進行分類損失；我們可能關心的其他指標（如準確性）往往會隨之提高。\n",
        "\n",
        "# 用 Sigmoid 函數做概率#\n",
        "\n",
        "交叉熵和準確度函數都需要概率作為輸入，即從 0 到 1 的數字。為了將密集層產生的實值輸出轉換為概率，我們附加了一種新的激活函數，**sigmoid 激活**。\n",
        "\n",
        "<figure style=\"padding: 1em;\">\n",
        "<img src=\"https://i.imgur.com/FYbRvJo.png\" width=\"400\" alt=\"Sigmoid 圖是一個“S”形，水平漸近線位於左側 0 和右側 1。 \">\n",
        "<figcaption style=\"textalign: center; font-style: italic\"><center>sigmoid函數將實數映射到區間$[0, 1]$中。</center></figcaption>\n",
        "</figure>\n",
        "\n",
        "為了得到最終的類預測，我們定義了一個*閾值(threshold)*概率。通常這將是 **0.5**，因此四捨五入將為我們提供正確的類：低於 0.5 表示標籤為 0 的類，而 0.5 或以上表示標籤為 1 的類。Keras 默認使用 [accuracy metric] 的閾值是 0.5 （https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy）。\n",
        "\n",
        "# 範例 - 二進制分類 #\n",
        "\n",
        "現在讓我們試試吧！\n",
        "\n",
        "[Ionosphere](https://archive.ics.uci.edu/ml/datasets/Ionosphere) 數據集包含從聚焦於地球大氣層電離層的雷達信號中獲得的特徵。任務是確定信號是否顯示某些物體的存在，或者只是空的空氣。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d1fbafc7",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2021-11-09T00:11:07.713957Z",
          "iopub.status.busy": "2021-11-09T00:11:07.713141Z",
          "iopub.status.idle": "2021-11-09T00:11:07.810527Z",
          "shell.execute_reply": "2021-11-09T00:11:07.809805Z"
        },
        "lines_to_next_cell": 0,
        "papermill": {
          "duration": 0.114198,
          "end_time": "2021-11-09T00:11:07.810720",
          "exception": false,
          "start_time": "2021-11-09T00:11:07.696522",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "d1fbafc7",
        "outputId": "93d2e130-7bcd-4480-f8d3-dea5da768300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f261e1fa-415f-4dd5-8ed7-4ca8a110aa69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f261e1fa-415f-4dd5-8ed7-4ca8a110aa69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f261e1fa-415f-4dd5-8ed7-4ca8a110aa69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f261e1fa-415f-4dd5-8ed7-4ca8a110aa69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   V1  V2       V3       V4       V5  ...      V31      V32      V33      V34  Class\n",
              "1   1   0  0.99539 -0.05889  0.85243  ...  0.42267 -0.54487  0.18641 -0.45300   good\n",
              "2   1   0  1.00000 -0.18829  0.93035  ... -0.16626 -0.06288 -0.13738 -0.02447    bad\n",
              "3   1   0  1.00000 -0.03365  1.00000  ...  0.60436 -0.24180  0.56045 -0.38238   good\n",
              "4   1   0  1.00000 -0.45161  1.00000  ...  0.25682  1.00000 -0.32382  1.00000    bad\n",
              "5   1   0  1.00000 -0.02401  0.94140  ... -0.05707 -0.59573 -0.04608 -0.65697   good\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "ion = pd.read_csv('/content/drive/MyDrive/ion.csv', index_col=0)\n",
        "display(ion.head())\n",
        "\n",
        "df = ion.copy()\n",
        "df['Class'] = df['Class'].map({'good': 0, 'bad': 1})\n",
        "\n",
        "df_train = df.sample(frac=0.7, random_state=0)\n",
        "df_valid = df.drop(df_train.index)\n",
        "\n",
        "max_ = df_train.max(axis=0)\n",
        "min_ = df_train.min(axis=0)\n",
        "\n",
        "df_train = (df_train - min_) / (max_ - min_)\n",
        "df_valid = (df_valid - min_) / (max_ - min_)\n",
        "df_train.dropna(axis=1, inplace=True) # drop the empty feature in column 2\n",
        "df_valid.dropna(axis=1, inplace=True)\n",
        "\n",
        "X_train = df_train.drop('Class', axis=1)\n",
        "X_valid = df_valid.drop('Class', axis=1)\n",
        "y_train = df_train['Class']\n",
        "y_valid = df_valid['Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cbc1d2a",
      "metadata": {
        "papermill": {
          "duration": 0.009076,
          "end_time": "2021-11-09T00:11:07.829535",
          "exception": false,
          "start_time": "2021-11-09T00:11:07.820459",
          "status": "completed"
        },
        "tags": [],
        "id": "7cbc1d2a"
      },
      "source": [
        "我們將像為迴歸任務所做的那樣定義我們的模型，但有一個例外。 在最後一層包括一個“sigmoid”激活，以便模型產生類概率。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4de6b16c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-09T00:11:07.856961Z",
          "iopub.status.busy": "2021-11-09T00:11:07.856068Z",
          "iopub.status.idle": "2021-11-09T00:11:14.427822Z",
          "shell.execute_reply": "2021-11-09T00:11:14.428367Z"
        },
        "papermill": {
          "duration": 6.589689,
          "end_time": "2021-11-09T00:11:14.428546",
          "exception": false,
          "start_time": "2021-11-09T00:11:07.838857",
          "status": "completed"
        },
        "tags": [],
        "id": "4de6b16c"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(4, activation='relu', input_shape=[33]),\n",
        "    layers.Dense(4, activation='relu'),    \n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c47e777b",
      "metadata": {
        "papermill": {
          "duration": 0.009532,
          "end_time": "2021-11-09T00:11:14.447945",
          "exception": false,
          "start_time": "2021-11-09T00:11:14.438413",
          "status": "completed"
        },
        "tags": [],
        "id": "c47e777b"
      },
      "source": [
        "使用`compile`方法將交叉熵損失和準確度指標添加到模型中。 對於二分類問題，請務必使用`'二進制'`版本。 （更多類的問題會略有不同。）Adam 優化器也適用於分類，所以我們就繼續下去。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "28ed606b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-09T00:11:14.471767Z",
          "iopub.status.busy": "2021-11-09T00:11:14.470638Z",
          "iopub.status.idle": "2021-11-09T00:11:14.483930Z",
          "shell.execute_reply": "2021-11-09T00:11:14.484536Z"
        },
        "papermill": {
          "duration": 0.027005,
          "end_time": "2021-11-09T00:11:14.484726",
          "exception": false,
          "start_time": "2021-11-09T00:11:14.457721",
          "status": "completed"
        },
        "tags": [],
        "id": "28ed606b"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['binary_accuracy'],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c0418c",
      "metadata": {
        "papermill": {
          "duration": 0.009483,
          "end_time": "2021-11-09T00:11:14.504108",
          "exception": false,
          "start_time": "2021-11-09T00:11:14.494625",
          "status": "completed"
        },
        "tags": [],
        "id": "a0c0418c"
      },
      "source": [
        "這個特定問題中的模型可能需要相當多的 epoch 才能完成訓練，因此為了方便起見，我們將包含一個提前停止回調。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6445156a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-09T00:11:14.527966Z",
          "iopub.status.busy": "2021-11-09T00:11:14.526929Z",
          "iopub.status.idle": "2021-11-09T00:11:17.676785Z",
          "shell.execute_reply": "2021-11-09T00:11:17.676199Z"
        },
        "papermill": {
          "duration": 3.162883,
          "end_time": "2021-11-09T00:11:17.676939",
          "exception": false,
          "start_time": "2021-11-09T00:11:14.514056",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6445156a",
        "outputId": "4c1bd47b-4712-4435-c3a2-cb09527e48ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.6639 - binary_accuracy: 0.7236 - val_loss: 0.6730 - val_binary_accuracy: 0.7048\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6635 - binary_accuracy: 0.7236 - val_loss: 0.6730 - val_binary_accuracy: 0.7048\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6630 - binary_accuracy: 0.7195 - val_loss: 0.6730 - val_binary_accuracy: 0.7238\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6625 - binary_accuracy: 0.7195 - val_loss: 0.6730 - val_binary_accuracy: 0.7238\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6621 - binary_accuracy: 0.7154 - val_loss: 0.6730 - val_binary_accuracy: 0.7048\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6616 - binary_accuracy: 0.7195 - val_loss: 0.6731 - val_binary_accuracy: 0.7048\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6611 - binary_accuracy: 0.7154 - val_loss: 0.6733 - val_binary_accuracy: 0.6952\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6607 - binary_accuracy: 0.7154 - val_loss: 0.6734 - val_binary_accuracy: 0.6952\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6603 - binary_accuracy: 0.7195 - val_loss: 0.6736 - val_binary_accuracy: 0.6952\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6600 - binary_accuracy: 0.7154 - val_loss: 0.6738 - val_binary_accuracy: 0.6952\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6597 - binary_accuracy: 0.7154 - val_loss: 0.6739 - val_binary_accuracy: 0.6952\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6594 - binary_accuracy: 0.7033 - val_loss: 0.6740 - val_binary_accuracy: 0.6952\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6591 - binary_accuracy: 0.6992 - val_loss: 0.6739 - val_binary_accuracy: 0.6952\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6588 - binary_accuracy: 0.6951 - val_loss: 0.6738 - val_binary_accuracy: 0.6952\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6584 - binary_accuracy: 0.6951 - val_loss: 0.6734 - val_binary_accuracy: 0.6952\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6581 - binary_accuracy: 0.6911 - val_loss: 0.6730 - val_binary_accuracy: 0.7048\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6577 - binary_accuracy: 0.6951 - val_loss: 0.6725 - val_binary_accuracy: 0.6952\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6573 - binary_accuracy: 0.6951 - val_loss: 0.6719 - val_binary_accuracy: 0.6952\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6569 - binary_accuracy: 0.6951 - val_loss: 0.6712 - val_binary_accuracy: 0.7048\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6565 - binary_accuracy: 0.7033 - val_loss: 0.6706 - val_binary_accuracy: 0.7048\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6561 - binary_accuracy: 0.7033 - val_loss: 0.6699 - val_binary_accuracy: 0.7048\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6557 - binary_accuracy: 0.7114 - val_loss: 0.6693 - val_binary_accuracy: 0.7048\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6553 - binary_accuracy: 0.7195 - val_loss: 0.6687 - val_binary_accuracy: 0.7143\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6550 - binary_accuracy: 0.7236 - val_loss: 0.6682 - val_binary_accuracy: 0.7143\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6546 - binary_accuracy: 0.7276 - val_loss: 0.6678 - val_binary_accuracy: 0.7143\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6543 - binary_accuracy: 0.7276 - val_loss: 0.6674 - val_binary_accuracy: 0.7238\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6539 - binary_accuracy: 0.7276 - val_loss: 0.6670 - val_binary_accuracy: 0.7333\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6536 - binary_accuracy: 0.7276 - val_loss: 0.6667 - val_binary_accuracy: 0.7333\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6532 - binary_accuracy: 0.7317 - val_loss: 0.6664 - val_binary_accuracy: 0.7429\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6528 - binary_accuracy: 0.7276 - val_loss: 0.6661 - val_binary_accuracy: 0.7333\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6524 - binary_accuracy: 0.7276 - val_loss: 0.6659 - val_binary_accuracy: 0.7333\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6520 - binary_accuracy: 0.7276 - val_loss: 0.6656 - val_binary_accuracy: 0.7333\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6517 - binary_accuracy: 0.7276 - val_loss: 0.6654 - val_binary_accuracy: 0.7429\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6513 - binary_accuracy: 0.7276 - val_loss: 0.6651 - val_binary_accuracy: 0.7524\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6509 - binary_accuracy: 0.7276 - val_loss: 0.6648 - val_binary_accuracy: 0.7524\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6505 - binary_accuracy: 0.7317 - val_loss: 0.6644 - val_binary_accuracy: 0.7524\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6502 - binary_accuracy: 0.7276 - val_loss: 0.6641 - val_binary_accuracy: 0.7524\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6498 - binary_accuracy: 0.7236 - val_loss: 0.6637 - val_binary_accuracy: 0.7524\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6494 - binary_accuracy: 0.7276 - val_loss: 0.6632 - val_binary_accuracy: 0.7524\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6490 - binary_accuracy: 0.7358 - val_loss: 0.6628 - val_binary_accuracy: 0.7524\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6486 - binary_accuracy: 0.7398 - val_loss: 0.6623 - val_binary_accuracy: 0.7619\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6482 - binary_accuracy: 0.7439 - val_loss: 0.6618 - val_binary_accuracy: 0.7619\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6478 - binary_accuracy: 0.7439 - val_loss: 0.6613 - val_binary_accuracy: 0.7714\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6474 - binary_accuracy: 0.7439 - val_loss: 0.6609 - val_binary_accuracy: 0.7714\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6470 - binary_accuracy: 0.7398 - val_loss: 0.6604 - val_binary_accuracy: 0.7714\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6466 - binary_accuracy: 0.7398 - val_loss: 0.6600 - val_binary_accuracy: 0.7714\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6462 - binary_accuracy: 0.7439 - val_loss: 0.6596 - val_binary_accuracy: 0.7810\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6458 - binary_accuracy: 0.7439 - val_loss: 0.6592 - val_binary_accuracy: 0.7810\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6454 - binary_accuracy: 0.7439 - val_loss: 0.6589 - val_binary_accuracy: 0.7810\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6449 - binary_accuracy: 0.7439 - val_loss: 0.6585 - val_binary_accuracy: 0.7810\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6445 - binary_accuracy: 0.7480 - val_loss: 0.6582 - val_binary_accuracy: 0.7810\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6441 - binary_accuracy: 0.7480 - val_loss: 0.6578 - val_binary_accuracy: 0.7810\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6437 - binary_accuracy: 0.7520 - val_loss: 0.6575 - val_binary_accuracy: 0.7810\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6432 - binary_accuracy: 0.7520 - val_loss: 0.6572 - val_binary_accuracy: 0.7810\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6428 - binary_accuracy: 0.7520 - val_loss: 0.6568 - val_binary_accuracy: 0.7810\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6424 - binary_accuracy: 0.7520 - val_loss: 0.6564 - val_binary_accuracy: 0.7810\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6419 - binary_accuracy: 0.7561 - val_loss: 0.6560 - val_binary_accuracy: 0.7810\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6415 - binary_accuracy: 0.7561 - val_loss: 0.6556 - val_binary_accuracy: 0.7810\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6410 - binary_accuracy: 0.7561 - val_loss: 0.6551 - val_binary_accuracy: 0.7810\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6406 - binary_accuracy: 0.7561 - val_loss: 0.6547 - val_binary_accuracy: 0.7810\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6401 - binary_accuracy: 0.7602 - val_loss: 0.6542 - val_binary_accuracy: 0.7810\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6397 - binary_accuracy: 0.7642 - val_loss: 0.6537 - val_binary_accuracy: 0.7810\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6392 - binary_accuracy: 0.7683 - val_loss: 0.6532 - val_binary_accuracy: 0.7810\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6388 - binary_accuracy: 0.7683 - val_loss: 0.6527 - val_binary_accuracy: 0.7810\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6383 - binary_accuracy: 0.7683 - val_loss: 0.6522 - val_binary_accuracy: 0.7810\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6379 - binary_accuracy: 0.7683 - val_loss: 0.6518 - val_binary_accuracy: 0.7905\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6374 - binary_accuracy: 0.7683 - val_loss: 0.6514 - val_binary_accuracy: 0.7905\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6369 - binary_accuracy: 0.7683 - val_loss: 0.6510 - val_binary_accuracy: 0.7905\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6365 - binary_accuracy: 0.7683 - val_loss: 0.6506 - val_binary_accuracy: 0.7905\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6360 - binary_accuracy: 0.7683 - val_loss: 0.6502 - val_binary_accuracy: 0.7905\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6355 - binary_accuracy: 0.7683 - val_loss: 0.6498 - val_binary_accuracy: 0.7905\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6351 - binary_accuracy: 0.7683 - val_loss: 0.6494 - val_binary_accuracy: 0.7905\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6346 - binary_accuracy: 0.7724 - val_loss: 0.6489 - val_binary_accuracy: 0.7905\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6341 - binary_accuracy: 0.7724 - val_loss: 0.6484 - val_binary_accuracy: 0.7905\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6337 - binary_accuracy: 0.7724 - val_loss: 0.6479 - val_binary_accuracy: 0.8000\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6332 - binary_accuracy: 0.7724 - val_loss: 0.6474 - val_binary_accuracy: 0.8000\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6327 - binary_accuracy: 0.7724 - val_loss: 0.6469 - val_binary_accuracy: 0.8095\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6322 - binary_accuracy: 0.7724 - val_loss: 0.6465 - val_binary_accuracy: 0.8095\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6317 - binary_accuracy: 0.7724 - val_loss: 0.6460 - val_binary_accuracy: 0.8095\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6312 - binary_accuracy: 0.7724 - val_loss: 0.6456 - val_binary_accuracy: 0.8095\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6307 - binary_accuracy: 0.7724 - val_loss: 0.6452 - val_binary_accuracy: 0.8095\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6302 - binary_accuracy: 0.7764 - val_loss: 0.6448 - val_binary_accuracy: 0.8095\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6297 - binary_accuracy: 0.7764 - val_loss: 0.6445 - val_binary_accuracy: 0.8095\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6292 - binary_accuracy: 0.7764 - val_loss: 0.6441 - val_binary_accuracy: 0.8095\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6287 - binary_accuracy: 0.7764 - val_loss: 0.6437 - val_binary_accuracy: 0.8095\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6282 - binary_accuracy: 0.7764 - val_loss: 0.6434 - val_binary_accuracy: 0.8095\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6277 - binary_accuracy: 0.7724 - val_loss: 0.6430 - val_binary_accuracy: 0.8095\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6272 - binary_accuracy: 0.7724 - val_loss: 0.6426 - val_binary_accuracy: 0.8095\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6267 - binary_accuracy: 0.7764 - val_loss: 0.6422 - val_binary_accuracy: 0.8095\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6261 - binary_accuracy: 0.7764 - val_loss: 0.6417 - val_binary_accuracy: 0.8095\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6256 - binary_accuracy: 0.7764 - val_loss: 0.6412 - val_binary_accuracy: 0.8095\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6250 - binary_accuracy: 0.7764 - val_loss: 0.6407 - val_binary_accuracy: 0.8095\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6245 - binary_accuracy: 0.7764 - val_loss: 0.6402 - val_binary_accuracy: 0.8095\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6240 - binary_accuracy: 0.7764 - val_loss: 0.6397 - val_binary_accuracy: 0.8095\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6234 - binary_accuracy: 0.7805 - val_loss: 0.6393 - val_binary_accuracy: 0.8095\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6229 - binary_accuracy: 0.7805 - val_loss: 0.6388 - val_binary_accuracy: 0.8095\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6223 - binary_accuracy: 0.7805 - val_loss: 0.6383 - val_binary_accuracy: 0.8095\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6217 - binary_accuracy: 0.7805 - val_loss: 0.6379 - val_binary_accuracy: 0.8095\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6212 - binary_accuracy: 0.7805 - val_loss: 0.6375 - val_binary_accuracy: 0.8095\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6206 - binary_accuracy: 0.7805 - val_loss: 0.6371 - val_binary_accuracy: 0.8095\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6200 - binary_accuracy: 0.7805 - val_loss: 0.6366 - val_binary_accuracy: 0.8095\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6195 - binary_accuracy: 0.7805 - val_loss: 0.6362 - val_binary_accuracy: 0.8095\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6189 - binary_accuracy: 0.7805 - val_loss: 0.6357 - val_binary_accuracy: 0.8095\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6183 - binary_accuracy: 0.7805 - val_loss: 0.6353 - val_binary_accuracy: 0.8095\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6177 - binary_accuracy: 0.7805 - val_loss: 0.6348 - val_binary_accuracy: 0.8095\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6171 - binary_accuracy: 0.7846 - val_loss: 0.6344 - val_binary_accuracy: 0.8095\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6165 - binary_accuracy: 0.7846 - val_loss: 0.6339 - val_binary_accuracy: 0.8095\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6159 - binary_accuracy: 0.7846 - val_loss: 0.6335 - val_binary_accuracy: 0.8095\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6153 - binary_accuracy: 0.7846 - val_loss: 0.6331 - val_binary_accuracy: 0.8095\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6147 - binary_accuracy: 0.7846 - val_loss: 0.6326 - val_binary_accuracy: 0.8095\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6141 - binary_accuracy: 0.7886 - val_loss: 0.6321 - val_binary_accuracy: 0.8095\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6135 - binary_accuracy: 0.7886 - val_loss: 0.6315 - val_binary_accuracy: 0.8095\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6129 - binary_accuracy: 0.7886 - val_loss: 0.6309 - val_binary_accuracy: 0.8095\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6122 - binary_accuracy: 0.7886 - val_loss: 0.6304 - val_binary_accuracy: 0.8190\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6116 - binary_accuracy: 0.7886 - val_loss: 0.6298 - val_binary_accuracy: 0.8190\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6110 - binary_accuracy: 0.7886 - val_loss: 0.6293 - val_binary_accuracy: 0.8286\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6104 - binary_accuracy: 0.7886 - val_loss: 0.6288 - val_binary_accuracy: 0.8286\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6097 - binary_accuracy: 0.7927 - val_loss: 0.6284 - val_binary_accuracy: 0.8286\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6091 - binary_accuracy: 0.7927 - val_loss: 0.6281 - val_binary_accuracy: 0.8190\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6084 - binary_accuracy: 0.7927 - val_loss: 0.6277 - val_binary_accuracy: 0.8095\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6077 - binary_accuracy: 0.7927 - val_loss: 0.6273 - val_binary_accuracy: 0.8095\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6071 - binary_accuracy: 0.7967 - val_loss: 0.6269 - val_binary_accuracy: 0.8095\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6064 - binary_accuracy: 0.7967 - val_loss: 0.6264 - val_binary_accuracy: 0.8095\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6058 - binary_accuracy: 0.7967 - val_loss: 0.6258 - val_binary_accuracy: 0.8095\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6051 - binary_accuracy: 0.7967 - val_loss: 0.6253 - val_binary_accuracy: 0.8095\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6045 - binary_accuracy: 0.7967 - val_loss: 0.6247 - val_binary_accuracy: 0.8095\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6038 - binary_accuracy: 0.7967 - val_loss: 0.6241 - val_binary_accuracy: 0.8286\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6031 - binary_accuracy: 0.7967 - val_loss: 0.6236 - val_binary_accuracy: 0.8286\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6025 - binary_accuracy: 0.7967 - val_loss: 0.6231 - val_binary_accuracy: 0.8286\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6018 - binary_accuracy: 0.7967 - val_loss: 0.6227 - val_binary_accuracy: 0.8190\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6011 - binary_accuracy: 0.7967 - val_loss: 0.6223 - val_binary_accuracy: 0.8190\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6004 - binary_accuracy: 0.7927 - val_loss: 0.6217 - val_binary_accuracy: 0.8286\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5998 - binary_accuracy: 0.7967 - val_loss: 0.6211 - val_binary_accuracy: 0.8286\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5991 - binary_accuracy: 0.7967 - val_loss: 0.6205 - val_binary_accuracy: 0.8381\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5984 - binary_accuracy: 0.7967 - val_loss: 0.6199 - val_binary_accuracy: 0.8381\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5977 - binary_accuracy: 0.8008 - val_loss: 0.6195 - val_binary_accuracy: 0.8381\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5970 - binary_accuracy: 0.8008 - val_loss: 0.6190 - val_binary_accuracy: 0.8286\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5963 - binary_accuracy: 0.8008 - val_loss: 0.6185 - val_binary_accuracy: 0.8286\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5957 - binary_accuracy: 0.8008 - val_loss: 0.6179 - val_binary_accuracy: 0.8286\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5950 - binary_accuracy: 0.7967 - val_loss: 0.6172 - val_binary_accuracy: 0.8381\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5943 - binary_accuracy: 0.8008 - val_loss: 0.6167 - val_binary_accuracy: 0.8381\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5936 - binary_accuracy: 0.8049 - val_loss: 0.6161 - val_binary_accuracy: 0.8381\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5929 - binary_accuracy: 0.8049 - val_loss: 0.6156 - val_binary_accuracy: 0.8381\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5921 - binary_accuracy: 0.8008 - val_loss: 0.6150 - val_binary_accuracy: 0.8381\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5914 - binary_accuracy: 0.8049 - val_loss: 0.6145 - val_binary_accuracy: 0.8381\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5907 - binary_accuracy: 0.8089 - val_loss: 0.6138 - val_binary_accuracy: 0.8381\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5900 - binary_accuracy: 0.8089 - val_loss: 0.6132 - val_binary_accuracy: 0.8476\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5893 - binary_accuracy: 0.8130 - val_loss: 0.6125 - val_binary_accuracy: 0.8476\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5886 - binary_accuracy: 0.8130 - val_loss: 0.6119 - val_binary_accuracy: 0.8476\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5879 - binary_accuracy: 0.8171 - val_loss: 0.6114 - val_binary_accuracy: 0.8476\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5872 - binary_accuracy: 0.8171 - val_loss: 0.6108 - val_binary_accuracy: 0.8476\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5864 - binary_accuracy: 0.8171 - val_loss: 0.6102 - val_binary_accuracy: 0.8381\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5857 - binary_accuracy: 0.8211 - val_loss: 0.6096 - val_binary_accuracy: 0.8381\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5850 - binary_accuracy: 0.8252 - val_loss: 0.6090 - val_binary_accuracy: 0.8381\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5843 - binary_accuracy: 0.8252 - val_loss: 0.6084 - val_binary_accuracy: 0.8381\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5835 - binary_accuracy: 0.8252 - val_loss: 0.6079 - val_binary_accuracy: 0.8381\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5828 - binary_accuracy: 0.8252 - val_loss: 0.6073 - val_binary_accuracy: 0.8381\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5820 - binary_accuracy: 0.8252 - val_loss: 0.6067 - val_binary_accuracy: 0.8381\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5813 - binary_accuracy: 0.8252 - val_loss: 0.6061 - val_binary_accuracy: 0.8381\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5805 - binary_accuracy: 0.8252 - val_loss: 0.6055 - val_binary_accuracy: 0.8381\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5798 - binary_accuracy: 0.8252 - val_loss: 0.6048 - val_binary_accuracy: 0.8381\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5790 - binary_accuracy: 0.8252 - val_loss: 0.6042 - val_binary_accuracy: 0.8381\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5782 - binary_accuracy: 0.8252 - val_loss: 0.6036 - val_binary_accuracy: 0.8381\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5774 - binary_accuracy: 0.8211 - val_loss: 0.6030 - val_binary_accuracy: 0.8286\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5767 - binary_accuracy: 0.8252 - val_loss: 0.6024 - val_binary_accuracy: 0.8286\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5759 - binary_accuracy: 0.8252 - val_loss: 0.6018 - val_binary_accuracy: 0.8286\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5752 - binary_accuracy: 0.8252 - val_loss: 0.6013 - val_binary_accuracy: 0.8381\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5744 - binary_accuracy: 0.8252 - val_loss: 0.6007 - val_binary_accuracy: 0.8381\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5736 - binary_accuracy: 0.8252 - val_loss: 0.6000 - val_binary_accuracy: 0.8381\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5729 - binary_accuracy: 0.8252 - val_loss: 0.5994 - val_binary_accuracy: 0.8381\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5721 - binary_accuracy: 0.8252 - val_loss: 0.5986 - val_binary_accuracy: 0.8381\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5713 - binary_accuracy: 0.8211 - val_loss: 0.5979 - val_binary_accuracy: 0.8381\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5705 - binary_accuracy: 0.8211 - val_loss: 0.5971 - val_binary_accuracy: 0.8381\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5697 - binary_accuracy: 0.8252 - val_loss: 0.5964 - val_binary_accuracy: 0.8381\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5689 - binary_accuracy: 0.8252 - val_loss: 0.5956 - val_binary_accuracy: 0.8476\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5681 - binary_accuracy: 0.8252 - val_loss: 0.5949 - val_binary_accuracy: 0.8571\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5674 - binary_accuracy: 0.8293 - val_loss: 0.5942 - val_binary_accuracy: 0.8571\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5666 - binary_accuracy: 0.8293 - val_loss: 0.5935 - val_binary_accuracy: 0.8571\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5658 - binary_accuracy: 0.8333 - val_loss: 0.5928 - val_binary_accuracy: 0.8571\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5650 - binary_accuracy: 0.8333 - val_loss: 0.5921 - val_binary_accuracy: 0.8571\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5642 - binary_accuracy: 0.8333 - val_loss: 0.5914 - val_binary_accuracy: 0.8571\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5634 - binary_accuracy: 0.8374 - val_loss: 0.5908 - val_binary_accuracy: 0.8571\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5625 - binary_accuracy: 0.8374 - val_loss: 0.5902 - val_binary_accuracy: 0.8476\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5617 - binary_accuracy: 0.8374 - val_loss: 0.5897 - val_binary_accuracy: 0.8571\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5609 - binary_accuracy: 0.8374 - val_loss: 0.5892 - val_binary_accuracy: 0.8571\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5601 - binary_accuracy: 0.8374 - val_loss: 0.5887 - val_binary_accuracy: 0.8571\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5593 - binary_accuracy: 0.8374 - val_loss: 0.5882 - val_binary_accuracy: 0.8571\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5585 - binary_accuracy: 0.8374 - val_loss: 0.5877 - val_binary_accuracy: 0.8571\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5577 - binary_accuracy: 0.8374 - val_loss: 0.5871 - val_binary_accuracy: 0.8571\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5569 - binary_accuracy: 0.8374 - val_loss: 0.5866 - val_binary_accuracy: 0.8571\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5560 - binary_accuracy: 0.8374 - val_loss: 0.5860 - val_binary_accuracy: 0.8571\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5552 - binary_accuracy: 0.8374 - val_loss: 0.5853 - val_binary_accuracy: 0.8571\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5544 - binary_accuracy: 0.8374 - val_loss: 0.5844 - val_binary_accuracy: 0.8571\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5536 - binary_accuracy: 0.8374 - val_loss: 0.5834 - val_binary_accuracy: 0.8571\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5527 - binary_accuracy: 0.8374 - val_loss: 0.5825 - val_binary_accuracy: 0.8571\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5519 - binary_accuracy: 0.8374 - val_loss: 0.5817 - val_binary_accuracy: 0.8571\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5511 - binary_accuracy: 0.8374 - val_loss: 0.5810 - val_binary_accuracy: 0.8571\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5503 - binary_accuracy: 0.8374 - val_loss: 0.5804 - val_binary_accuracy: 0.8571\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5494 - binary_accuracy: 0.8374 - val_loss: 0.5800 - val_binary_accuracy: 0.8571\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5486 - binary_accuracy: 0.8374 - val_loss: 0.5794 - val_binary_accuracy: 0.8571\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5478 - binary_accuracy: 0.8374 - val_loss: 0.5789 - val_binary_accuracy: 0.8571\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5469 - binary_accuracy: 0.8374 - val_loss: 0.5783 - val_binary_accuracy: 0.8571\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5461 - binary_accuracy: 0.8374 - val_loss: 0.5777 - val_binary_accuracy: 0.8571\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5452 - binary_accuracy: 0.8374 - val_loss: 0.5769 - val_binary_accuracy: 0.8571\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5444 - binary_accuracy: 0.8374 - val_loss: 0.5761 - val_binary_accuracy: 0.8571\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5436 - binary_accuracy: 0.8374 - val_loss: 0.5753 - val_binary_accuracy: 0.8571\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5427 - binary_accuracy: 0.8374 - val_loss: 0.5745 - val_binary_accuracy: 0.8571\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5419 - binary_accuracy: 0.8374 - val_loss: 0.5736 - val_binary_accuracy: 0.8571\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5410 - binary_accuracy: 0.8374 - val_loss: 0.5729 - val_binary_accuracy: 0.8571\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5402 - binary_accuracy: 0.8415 - val_loss: 0.5721 - val_binary_accuracy: 0.8571\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5393 - binary_accuracy: 0.8415 - val_loss: 0.5715 - val_binary_accuracy: 0.8571\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5385 - binary_accuracy: 0.8455 - val_loss: 0.5710 - val_binary_accuracy: 0.8571\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5376 - binary_accuracy: 0.8455 - val_loss: 0.5705 - val_binary_accuracy: 0.8571\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5367 - binary_accuracy: 0.8455 - val_loss: 0.5699 - val_binary_accuracy: 0.8571\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5359 - binary_accuracy: 0.8496 - val_loss: 0.5693 - val_binary_accuracy: 0.8571\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5350 - binary_accuracy: 0.8496 - val_loss: 0.5686 - val_binary_accuracy: 0.8571\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5342 - binary_accuracy: 0.8537 - val_loss: 0.5679 - val_binary_accuracy: 0.8667\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5333 - binary_accuracy: 0.8537 - val_loss: 0.5673 - val_binary_accuracy: 0.8667\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5325 - binary_accuracy: 0.8537 - val_loss: 0.5666 - val_binary_accuracy: 0.8667\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5316 - binary_accuracy: 0.8537 - val_loss: 0.5660 - val_binary_accuracy: 0.8667\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5308 - binary_accuracy: 0.8537 - val_loss: 0.5653 - val_binary_accuracy: 0.8667\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5299 - binary_accuracy: 0.8537 - val_loss: 0.5646 - val_binary_accuracy: 0.8667\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5290 - binary_accuracy: 0.8537 - val_loss: 0.5640 - val_binary_accuracy: 0.8667\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5282 - binary_accuracy: 0.8577 - val_loss: 0.5632 - val_binary_accuracy: 0.8667\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5273 - binary_accuracy: 0.8577 - val_loss: 0.5625 - val_binary_accuracy: 0.8667\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5264 - binary_accuracy: 0.8577 - val_loss: 0.5618 - val_binary_accuracy: 0.8667\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5256 - binary_accuracy: 0.8577 - val_loss: 0.5611 - val_binary_accuracy: 0.8667\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5247 - binary_accuracy: 0.8577 - val_loss: 0.5604 - val_binary_accuracy: 0.8667\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5239 - binary_accuracy: 0.8577 - val_loss: 0.5597 - val_binary_accuracy: 0.8667\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5230 - binary_accuracy: 0.8577 - val_loss: 0.5590 - val_binary_accuracy: 0.8667\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5221 - binary_accuracy: 0.8577 - val_loss: 0.5582 - val_binary_accuracy: 0.8667\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5213 - binary_accuracy: 0.8577 - val_loss: 0.5575 - val_binary_accuracy: 0.8667\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5204 - binary_accuracy: 0.8577 - val_loss: 0.5567 - val_binary_accuracy: 0.8667\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5195 - binary_accuracy: 0.8577 - val_loss: 0.5560 - val_binary_accuracy: 0.8667\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5187 - binary_accuracy: 0.8577 - val_loss: 0.5552 - val_binary_accuracy: 0.8667\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5178 - binary_accuracy: 0.8577 - val_loss: 0.5545 - val_binary_accuracy: 0.8667\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5169 - binary_accuracy: 0.8537 - val_loss: 0.5537 - val_binary_accuracy: 0.8762\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5161 - binary_accuracy: 0.8537 - val_loss: 0.5532 - val_binary_accuracy: 0.8667\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5152 - binary_accuracy: 0.8537 - val_loss: 0.5528 - val_binary_accuracy: 0.8667\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5143 - binary_accuracy: 0.8577 - val_loss: 0.5524 - val_binary_accuracy: 0.8667\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5134 - binary_accuracy: 0.8577 - val_loss: 0.5519 - val_binary_accuracy: 0.8667\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5126 - binary_accuracy: 0.8577 - val_loss: 0.5514 - val_binary_accuracy: 0.8667\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5117 - binary_accuracy: 0.8577 - val_loss: 0.5507 - val_binary_accuracy: 0.8667\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5108 - binary_accuracy: 0.8577 - val_loss: 0.5499 - val_binary_accuracy: 0.8667\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5099 - binary_accuracy: 0.8577 - val_loss: 0.5492 - val_binary_accuracy: 0.8667\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5090 - binary_accuracy: 0.8577 - val_loss: 0.5484 - val_binary_accuracy: 0.8667\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5081 - binary_accuracy: 0.8577 - val_loss: 0.5478 - val_binary_accuracy: 0.8667\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5072 - binary_accuracy: 0.8577 - val_loss: 0.5471 - val_binary_accuracy: 0.8857\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5063 - binary_accuracy: 0.8618 - val_loss: 0.5464 - val_binary_accuracy: 0.8857\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5054 - binary_accuracy: 0.8618 - val_loss: 0.5459 - val_binary_accuracy: 0.8857\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5045 - binary_accuracy: 0.8618 - val_loss: 0.5452 - val_binary_accuracy: 0.8857\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5036 - binary_accuracy: 0.8618 - val_loss: 0.5445 - val_binary_accuracy: 0.8857\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5027 - binary_accuracy: 0.8618 - val_loss: 0.5439 - val_binary_accuracy: 0.8857\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5018 - binary_accuracy: 0.8618 - val_loss: 0.5433 - val_binary_accuracy: 0.8857\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5009 - binary_accuracy: 0.8659 - val_loss: 0.5427 - val_binary_accuracy: 0.8857\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5000 - binary_accuracy: 0.8699 - val_loss: 0.5420 - val_binary_accuracy: 0.8857\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4991 - binary_accuracy: 0.8699 - val_loss: 0.5412 - val_binary_accuracy: 0.8857\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4982 - binary_accuracy: 0.8699 - val_loss: 0.5405 - val_binary_accuracy: 0.8857\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4972 - binary_accuracy: 0.8699 - val_loss: 0.5398 - val_binary_accuracy: 0.8857\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4963 - binary_accuracy: 0.8699 - val_loss: 0.5391 - val_binary_accuracy: 0.8857\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4954 - binary_accuracy: 0.8740 - val_loss: 0.5385 - val_binary_accuracy: 0.8857\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4945 - binary_accuracy: 0.8740 - val_loss: 0.5379 - val_binary_accuracy: 0.8857\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4936 - binary_accuracy: 0.8740 - val_loss: 0.5372 - val_binary_accuracy: 0.8857\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4927 - binary_accuracy: 0.8740 - val_loss: 0.5364 - val_binary_accuracy: 0.8857\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4918 - binary_accuracy: 0.8780 - val_loss: 0.5356 - val_binary_accuracy: 0.8857\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4909 - binary_accuracy: 0.8780 - val_loss: 0.5348 - val_binary_accuracy: 0.8857\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4899 - binary_accuracy: 0.8780 - val_loss: 0.5339 - val_binary_accuracy: 0.8857\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4890 - binary_accuracy: 0.8780 - val_loss: 0.5330 - val_binary_accuracy: 0.8857\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4881 - binary_accuracy: 0.8780 - val_loss: 0.5322 - val_binary_accuracy: 0.8857\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4872 - binary_accuracy: 0.8780 - val_loss: 0.5314 - val_binary_accuracy: 0.8857\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4863 - binary_accuracy: 0.8780 - val_loss: 0.5306 - val_binary_accuracy: 0.8857\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4854 - binary_accuracy: 0.8780 - val_loss: 0.5301 - val_binary_accuracy: 0.8857\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4844 - binary_accuracy: 0.8780 - val_loss: 0.5296 - val_binary_accuracy: 0.8857\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4835 - binary_accuracy: 0.8821 - val_loss: 0.5291 - val_binary_accuracy: 0.8857\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4826 - binary_accuracy: 0.8862 - val_loss: 0.5284 - val_binary_accuracy: 0.8857\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4817 - binary_accuracy: 0.8862 - val_loss: 0.5274 - val_binary_accuracy: 0.8857\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4808 - binary_accuracy: 0.8862 - val_loss: 0.5265 - val_binary_accuracy: 0.8857\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4799 - binary_accuracy: 0.8862 - val_loss: 0.5258 - val_binary_accuracy: 0.8857\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4790 - binary_accuracy: 0.8862 - val_loss: 0.5252 - val_binary_accuracy: 0.8857\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4780 - binary_accuracy: 0.8943 - val_loss: 0.5246 - val_binary_accuracy: 0.8857\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4771 - binary_accuracy: 0.8943 - val_loss: 0.5240 - val_binary_accuracy: 0.8857\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4762 - binary_accuracy: 0.8943 - val_loss: 0.5231 - val_binary_accuracy: 0.8857\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4753 - binary_accuracy: 0.8943 - val_loss: 0.5224 - val_binary_accuracy: 0.8857\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4744 - binary_accuracy: 0.8943 - val_loss: 0.5216 - val_binary_accuracy: 0.8857\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4735 - binary_accuracy: 0.8943 - val_loss: 0.5208 - val_binary_accuracy: 0.8857\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4726 - binary_accuracy: 0.8943 - val_loss: 0.5201 - val_binary_accuracy: 0.8857\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.4716 - binary_accuracy: 0.8943 - val_loss: 0.5194 - val_binary_accuracy: 0.8857\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4707 - binary_accuracy: 0.8943 - val_loss: 0.5189 - val_binary_accuracy: 0.8857\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4698 - binary_accuracy: 0.8943 - val_loss: 0.5182 - val_binary_accuracy: 0.8857\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4689 - binary_accuracy: 0.8943 - val_loss: 0.5174 - val_binary_accuracy: 0.8857\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4680 - binary_accuracy: 0.8943 - val_loss: 0.5164 - val_binary_accuracy: 0.8857\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.4671 - binary_accuracy: 0.8943 - val_loss: 0.5155 - val_binary_accuracy: 0.8857\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4661 - binary_accuracy: 0.8984 - val_loss: 0.5147 - val_binary_accuracy: 0.8857\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4652 - binary_accuracy: 0.8984 - val_loss: 0.5139 - val_binary_accuracy: 0.8857\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4643 - binary_accuracy: 0.8984 - val_loss: 0.5131 - val_binary_accuracy: 0.8857\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4633 - binary_accuracy: 0.8984 - val_loss: 0.5124 - val_binary_accuracy: 0.8857\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4624 - binary_accuracy: 0.8984 - val_loss: 0.5117 - val_binary_accuracy: 0.8857\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4615 - binary_accuracy: 0.8984 - val_loss: 0.5110 - val_binary_accuracy: 0.8857\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4605 - binary_accuracy: 0.8984 - val_loss: 0.5102 - val_binary_accuracy: 0.8857\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4596 - binary_accuracy: 0.8984 - val_loss: 0.5093 - val_binary_accuracy: 0.8857\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4587 - binary_accuracy: 0.8984 - val_loss: 0.5084 - val_binary_accuracy: 0.8857\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4577 - binary_accuracy: 0.8984 - val_loss: 0.5075 - val_binary_accuracy: 0.8857\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4568 - binary_accuracy: 0.8984 - val_loss: 0.5066 - val_binary_accuracy: 0.8857\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4558 - binary_accuracy: 0.8984 - val_loss: 0.5057 - val_binary_accuracy: 0.8857\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4549 - binary_accuracy: 0.8984 - val_loss: 0.5049 - val_binary_accuracy: 0.8857\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4539 - binary_accuracy: 0.8984 - val_loss: 0.5043 - val_binary_accuracy: 0.8857\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4530 - binary_accuracy: 0.8984 - val_loss: 0.5037 - val_binary_accuracy: 0.8857\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4520 - binary_accuracy: 0.8984 - val_loss: 0.5029 - val_binary_accuracy: 0.8857\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4511 - binary_accuracy: 0.8984 - val_loss: 0.5020 - val_binary_accuracy: 0.8857\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4501 - binary_accuracy: 0.8984 - val_loss: 0.5012 - val_binary_accuracy: 0.8857\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4492 - binary_accuracy: 0.8984 - val_loss: 0.5004 - val_binary_accuracy: 0.8857\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4482 - binary_accuracy: 0.8984 - val_loss: 0.4995 - val_binary_accuracy: 0.8857\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4472 - binary_accuracy: 0.8984 - val_loss: 0.4988 - val_binary_accuracy: 0.8857\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4463 - binary_accuracy: 0.9024 - val_loss: 0.4980 - val_binary_accuracy: 0.8857\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4453 - binary_accuracy: 0.9024 - val_loss: 0.4971 - val_binary_accuracy: 0.8857\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4443 - binary_accuracy: 0.9024 - val_loss: 0.4962 - val_binary_accuracy: 0.8857\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4434 - binary_accuracy: 0.9024 - val_loss: 0.4955 - val_binary_accuracy: 0.8857\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4424 - binary_accuracy: 0.9024 - val_loss: 0.4948 - val_binary_accuracy: 0.8857\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4415 - binary_accuracy: 0.9106 - val_loss: 0.4940 - val_binary_accuracy: 0.8857\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4405 - binary_accuracy: 0.9106 - val_loss: 0.4932 - val_binary_accuracy: 0.8857\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4395 - binary_accuracy: 0.9106 - val_loss: 0.4923 - val_binary_accuracy: 0.8857\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.4385 - binary_accuracy: 0.9106 - val_loss: 0.4915 - val_binary_accuracy: 0.8857\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4375 - binary_accuracy: 0.9106 - val_loss: 0.4908 - val_binary_accuracy: 0.8857\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4366 - binary_accuracy: 0.9106 - val_loss: 0.4900 - val_binary_accuracy: 0.8857\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4356 - binary_accuracy: 0.9106 - val_loss: 0.4892 - val_binary_accuracy: 0.8857\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4346 - binary_accuracy: 0.9146 - val_loss: 0.4884 - val_binary_accuracy: 0.8857\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4336 - binary_accuracy: 0.9146 - val_loss: 0.4876 - val_binary_accuracy: 0.8857\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4326 - binary_accuracy: 0.9146 - val_loss: 0.4868 - val_binary_accuracy: 0.8857\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4316 - binary_accuracy: 0.9146 - val_loss: 0.4860 - val_binary_accuracy: 0.8857\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4306 - binary_accuracy: 0.9146 - val_loss: 0.4853 - val_binary_accuracy: 0.8857\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4296 - binary_accuracy: 0.9146 - val_loss: 0.4845 - val_binary_accuracy: 0.8857\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4286 - binary_accuracy: 0.9146 - val_loss: 0.4837 - val_binary_accuracy: 0.8857\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4276 - binary_accuracy: 0.9146 - val_loss: 0.4828 - val_binary_accuracy: 0.8857\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4266 - binary_accuracy: 0.9146 - val_loss: 0.4822 - val_binary_accuracy: 0.8857\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4256 - binary_accuracy: 0.9228 - val_loss: 0.4814 - val_binary_accuracy: 0.8857\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4246 - binary_accuracy: 0.9228 - val_loss: 0.4805 - val_binary_accuracy: 0.8857\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4237 - binary_accuracy: 0.9228 - val_loss: 0.4798 - val_binary_accuracy: 0.8857\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4227 - binary_accuracy: 0.9228 - val_loss: 0.4791 - val_binary_accuracy: 0.8857\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4217 - binary_accuracy: 0.9228 - val_loss: 0.4784 - val_binary_accuracy: 0.8857\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4207 - binary_accuracy: 0.9228 - val_loss: 0.4776 - val_binary_accuracy: 0.8857\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4197 - binary_accuracy: 0.9228 - val_loss: 0.4768 - val_binary_accuracy: 0.8857\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4187 - binary_accuracy: 0.9228 - val_loss: 0.4761 - val_binary_accuracy: 0.8857\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4177 - binary_accuracy: 0.9228 - val_loss: 0.4754 - val_binary_accuracy: 0.8857\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4167 - binary_accuracy: 0.9228 - val_loss: 0.4747 - val_binary_accuracy: 0.8857\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4157 - binary_accuracy: 0.9268 - val_loss: 0.4741 - val_binary_accuracy: 0.8857\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4148 - binary_accuracy: 0.9268 - val_loss: 0.4735 - val_binary_accuracy: 0.8857\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4138 - binary_accuracy: 0.9268 - val_loss: 0.4728 - val_binary_accuracy: 0.8857\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4128 - binary_accuracy: 0.9268 - val_loss: 0.4721 - val_binary_accuracy: 0.8857\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4118 - binary_accuracy: 0.9268 - val_loss: 0.4712 - val_binary_accuracy: 0.8857\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4108 - binary_accuracy: 0.9268 - val_loss: 0.4704 - val_binary_accuracy: 0.8857\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.4099 - binary_accuracy: 0.9268 - val_loss: 0.4695 - val_binary_accuracy: 0.8857\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4089 - binary_accuracy: 0.9309 - val_loss: 0.4687 - val_binary_accuracy: 0.8857\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4079 - binary_accuracy: 0.9309 - val_loss: 0.4679 - val_binary_accuracy: 0.8857\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4070 - binary_accuracy: 0.9309 - val_loss: 0.4671 - val_binary_accuracy: 0.8857\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4060 - binary_accuracy: 0.9309 - val_loss: 0.4664 - val_binary_accuracy: 0.8857\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4050 - binary_accuracy: 0.9309 - val_loss: 0.4658 - val_binary_accuracy: 0.8857\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4041 - binary_accuracy: 0.9309 - val_loss: 0.4652 - val_binary_accuracy: 0.8857\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4031 - binary_accuracy: 0.9309 - val_loss: 0.4645 - val_binary_accuracy: 0.8857\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4021 - binary_accuracy: 0.9309 - val_loss: 0.4638 - val_binary_accuracy: 0.8857\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4012 - binary_accuracy: 0.9309 - val_loss: 0.4631 - val_binary_accuracy: 0.8857\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4002 - binary_accuracy: 0.9309 - val_loss: 0.4623 - val_binary_accuracy: 0.8857\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3993 - binary_accuracy: 0.9309 - val_loss: 0.4617 - val_binary_accuracy: 0.8857\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3983 - binary_accuracy: 0.9309 - val_loss: 0.4610 - val_binary_accuracy: 0.8857\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3974 - binary_accuracy: 0.9309 - val_loss: 0.4603 - val_binary_accuracy: 0.8857\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3964 - binary_accuracy: 0.9309 - val_loss: 0.4596 - val_binary_accuracy: 0.8857\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3955 - binary_accuracy: 0.9309 - val_loss: 0.4588 - val_binary_accuracy: 0.8857\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3945 - binary_accuracy: 0.9309 - val_loss: 0.4580 - val_binary_accuracy: 0.8857\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3936 - binary_accuracy: 0.9309 - val_loss: 0.4573 - val_binary_accuracy: 0.8857\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3926 - binary_accuracy: 0.9309 - val_loss: 0.4565 - val_binary_accuracy: 0.8857\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.3917 - binary_accuracy: 0.9309 - val_loss: 0.4559 - val_binary_accuracy: 0.8857\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3907 - binary_accuracy: 0.9309 - val_loss: 0.4553 - val_binary_accuracy: 0.8857\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3898 - binary_accuracy: 0.9309 - val_loss: 0.4547 - val_binary_accuracy: 0.8857\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3888 - binary_accuracy: 0.9268 - val_loss: 0.4541 - val_binary_accuracy: 0.8857\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3879 - binary_accuracy: 0.9268 - val_loss: 0.4535 - val_binary_accuracy: 0.8857\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3869 - binary_accuracy: 0.9268 - val_loss: 0.4527 - val_binary_accuracy: 0.8857\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3860 - binary_accuracy: 0.9268 - val_loss: 0.4518 - val_binary_accuracy: 0.8857\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3850 - binary_accuracy: 0.9268 - val_loss: 0.4509 - val_binary_accuracy: 0.8857\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3841 - binary_accuracy: 0.9268 - val_loss: 0.4501 - val_binary_accuracy: 0.8857\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3832 - binary_accuracy: 0.9268 - val_loss: 0.4496 - val_binary_accuracy: 0.8857\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3822 - binary_accuracy: 0.9268 - val_loss: 0.4491 - val_binary_accuracy: 0.8857\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3813 - binary_accuracy: 0.9268 - val_loss: 0.4485 - val_binary_accuracy: 0.8857\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3804 - binary_accuracy: 0.9268 - val_loss: 0.4476 - val_binary_accuracy: 0.8857\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3794 - binary_accuracy: 0.9268 - val_loss: 0.4467 - val_binary_accuracy: 0.8857\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3785 - binary_accuracy: 0.9268 - val_loss: 0.4460 - val_binary_accuracy: 0.8857\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3776 - binary_accuracy: 0.9268 - val_loss: 0.4454 - val_binary_accuracy: 0.8857\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3766 - binary_accuracy: 0.9268 - val_loss: 0.4448 - val_binary_accuracy: 0.8857\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3757 - binary_accuracy: 0.9268 - val_loss: 0.4443 - val_binary_accuracy: 0.8857\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3748 - binary_accuracy: 0.9268 - val_loss: 0.4436 - val_binary_accuracy: 0.8857\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3739 - binary_accuracy: 0.9268 - val_loss: 0.4428 - val_binary_accuracy: 0.8857\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3730 - binary_accuracy: 0.9268 - val_loss: 0.4419 - val_binary_accuracy: 0.8857\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3721 - binary_accuracy: 0.9268 - val_loss: 0.4412 - val_binary_accuracy: 0.8952\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3711 - binary_accuracy: 0.9268 - val_loss: 0.4405 - val_binary_accuracy: 0.8952\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.3702 - binary_accuracy: 0.9268 - val_loss: 0.4400 - val_binary_accuracy: 0.8952\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3693 - binary_accuracy: 0.9268 - val_loss: 0.4394 - val_binary_accuracy: 0.8952\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3684 - binary_accuracy: 0.9268 - val_loss: 0.4388 - val_binary_accuracy: 0.8952\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.3675 - binary_accuracy: 0.9268 - val_loss: 0.4382 - val_binary_accuracy: 0.8952\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3666 - binary_accuracy: 0.9268 - val_loss: 0.4376 - val_binary_accuracy: 0.8952\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3657 - binary_accuracy: 0.9268 - val_loss: 0.4369 - val_binary_accuracy: 0.8952\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3648 - binary_accuracy: 0.9309 - val_loss: 0.4361 - val_binary_accuracy: 0.8952\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3639 - binary_accuracy: 0.9309 - val_loss: 0.4355 - val_binary_accuracy: 0.8952\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3631 - binary_accuracy: 0.9309 - val_loss: 0.4348 - val_binary_accuracy: 0.8952\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3622 - binary_accuracy: 0.9309 - val_loss: 0.4341 - val_binary_accuracy: 0.8952\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3613 - binary_accuracy: 0.9268 - val_loss: 0.4334 - val_binary_accuracy: 0.8952\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3604 - binary_accuracy: 0.9268 - val_loss: 0.4327 - val_binary_accuracy: 0.8952\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3595 - binary_accuracy: 0.9268 - val_loss: 0.4320 - val_binary_accuracy: 0.8952\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3586 - binary_accuracy: 0.9268 - val_loss: 0.4312 - val_binary_accuracy: 0.8952\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3577 - binary_accuracy: 0.9268 - val_loss: 0.4305 - val_binary_accuracy: 0.8952\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3568 - binary_accuracy: 0.9268 - val_loss: 0.4299 - val_binary_accuracy: 0.8952\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3559 - binary_accuracy: 0.9309 - val_loss: 0.4293 - val_binary_accuracy: 0.8952\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3550 - binary_accuracy: 0.9309 - val_loss: 0.4287 - val_binary_accuracy: 0.8952\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3541 - binary_accuracy: 0.9309 - val_loss: 0.4281 - val_binary_accuracy: 0.8857\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3532 - binary_accuracy: 0.9309 - val_loss: 0.4275 - val_binary_accuracy: 0.8857\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3523 - binary_accuracy: 0.9309 - val_loss: 0.4268 - val_binary_accuracy: 0.8857\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3514 - binary_accuracy: 0.9309 - val_loss: 0.4260 - val_binary_accuracy: 0.8857\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3505 - binary_accuracy: 0.9309 - val_loss: 0.4252 - val_binary_accuracy: 0.8952\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3496 - binary_accuracy: 0.9309 - val_loss: 0.4244 - val_binary_accuracy: 0.8952\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3487 - binary_accuracy: 0.9309 - val_loss: 0.4236 - val_binary_accuracy: 0.8952\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3478 - binary_accuracy: 0.9350 - val_loss: 0.4228 - val_binary_accuracy: 0.8952\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3469 - binary_accuracy: 0.9350 - val_loss: 0.4222 - val_binary_accuracy: 0.8952\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3460 - binary_accuracy: 0.9350 - val_loss: 0.4216 - val_binary_accuracy: 0.8857\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3451 - binary_accuracy: 0.9350 - val_loss: 0.4211 - val_binary_accuracy: 0.8857\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3442 - binary_accuracy: 0.9350 - val_loss: 0.4204 - val_binary_accuracy: 0.8857\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3433 - binary_accuracy: 0.9350 - val_loss: 0.4197 - val_binary_accuracy: 0.8857\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3424 - binary_accuracy: 0.9350 - val_loss: 0.4192 - val_binary_accuracy: 0.8857\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3416 - binary_accuracy: 0.9350 - val_loss: 0.4185 - val_binary_accuracy: 0.8857\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3407 - binary_accuracy: 0.9350 - val_loss: 0.4178 - val_binary_accuracy: 0.8857\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3398 - binary_accuracy: 0.9390 - val_loss: 0.4170 - val_binary_accuracy: 0.8857\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3389 - binary_accuracy: 0.9431 - val_loss: 0.4163 - val_binary_accuracy: 0.8857\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3380 - binary_accuracy: 0.9431 - val_loss: 0.4158 - val_binary_accuracy: 0.8857\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3371 - binary_accuracy: 0.9431 - val_loss: 0.4152 - val_binary_accuracy: 0.8857\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3362 - binary_accuracy: 0.9431 - val_loss: 0.4145 - val_binary_accuracy: 0.8857\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3354 - binary_accuracy: 0.9431 - val_loss: 0.4139 - val_binary_accuracy: 0.8857\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3345 - binary_accuracy: 0.9431 - val_loss: 0.4131 - val_binary_accuracy: 0.8857\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3336 - binary_accuracy: 0.9431 - val_loss: 0.4124 - val_binary_accuracy: 0.8857\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3327 - binary_accuracy: 0.9431 - val_loss: 0.4117 - val_binary_accuracy: 0.8857\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3319 - binary_accuracy: 0.9431 - val_loss: 0.4110 - val_binary_accuracy: 0.8857\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3310 - binary_accuracy: 0.9431 - val_loss: 0.4103 - val_binary_accuracy: 0.8857\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.3301 - binary_accuracy: 0.9431 - val_loss: 0.4096 - val_binary_accuracy: 0.8857\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3293 - binary_accuracy: 0.9431 - val_loss: 0.4089 - val_binary_accuracy: 0.8857\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3284 - binary_accuracy: 0.9431 - val_loss: 0.4082 - val_binary_accuracy: 0.8952\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3275 - binary_accuracy: 0.9431 - val_loss: 0.4074 - val_binary_accuracy: 0.8952\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3267 - binary_accuracy: 0.9431 - val_loss: 0.4066 - val_binary_accuracy: 0.8952\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3258 - binary_accuracy: 0.9431 - val_loss: 0.4059 - val_binary_accuracy: 0.8952\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3250 - binary_accuracy: 0.9431 - val_loss: 0.4050 - val_binary_accuracy: 0.8952\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3241 - binary_accuracy: 0.9431 - val_loss: 0.4045 - val_binary_accuracy: 0.8952\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3233 - binary_accuracy: 0.9431 - val_loss: 0.4042 - val_binary_accuracy: 0.8952\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3224 - binary_accuracy: 0.9431 - val_loss: 0.4038 - val_binary_accuracy: 0.8857\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3216 - binary_accuracy: 0.9431 - val_loss: 0.4033 - val_binary_accuracy: 0.8857\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3208 - binary_accuracy: 0.9431 - val_loss: 0.4026 - val_binary_accuracy: 0.8857\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3199 - binary_accuracy: 0.9431 - val_loss: 0.4019 - val_binary_accuracy: 0.8857\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3191 - binary_accuracy: 0.9431 - val_loss: 0.4012 - val_binary_accuracy: 0.8857\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3183 - binary_accuracy: 0.9431 - val_loss: 0.4005 - val_binary_accuracy: 0.8857\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3175 - binary_accuracy: 0.9431 - val_loss: 0.4000 - val_binary_accuracy: 0.8857\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3167 - binary_accuracy: 0.9431 - val_loss: 0.3994 - val_binary_accuracy: 0.8857\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3158 - binary_accuracy: 0.9431 - val_loss: 0.3989 - val_binary_accuracy: 0.8857\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3150 - binary_accuracy: 0.9431 - val_loss: 0.3984 - val_binary_accuracy: 0.8857\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3142 - binary_accuracy: 0.9431 - val_loss: 0.3978 - val_binary_accuracy: 0.8857\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.3134 - binary_accuracy: 0.9431 - val_loss: 0.3972 - val_binary_accuracy: 0.8857\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3126 - binary_accuracy: 0.9431 - val_loss: 0.3966 - val_binary_accuracy: 0.8857\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3118 - binary_accuracy: 0.9431 - val_loss: 0.3959 - val_binary_accuracy: 0.8857\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3110 - binary_accuracy: 0.9431 - val_loss: 0.3952 - val_binary_accuracy: 0.8857\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3102 - binary_accuracy: 0.9431 - val_loss: 0.3947 - val_binary_accuracy: 0.8857\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3095 - binary_accuracy: 0.9431 - val_loss: 0.3942 - val_binary_accuracy: 0.8857\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3087 - binary_accuracy: 0.9431 - val_loss: 0.3938 - val_binary_accuracy: 0.8857\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3079 - binary_accuracy: 0.9431 - val_loss: 0.3933 - val_binary_accuracy: 0.8857\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3071 - binary_accuracy: 0.9431 - val_loss: 0.3926 - val_binary_accuracy: 0.8857\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3063 - binary_accuracy: 0.9431 - val_loss: 0.3920 - val_binary_accuracy: 0.8857\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3056 - binary_accuracy: 0.9431 - val_loss: 0.3915 - val_binary_accuracy: 0.8857\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3048 - binary_accuracy: 0.9431 - val_loss: 0.3910 - val_binary_accuracy: 0.8857\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3040 - binary_accuracy: 0.9431 - val_loss: 0.3905 - val_binary_accuracy: 0.8857\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3033 - binary_accuracy: 0.9431 - val_loss: 0.3900 - val_binary_accuracy: 0.8857\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3025 - binary_accuracy: 0.9431 - val_loss: 0.3894 - val_binary_accuracy: 0.8857\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3017 - binary_accuracy: 0.9431 - val_loss: 0.3889 - val_binary_accuracy: 0.8857\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3010 - binary_accuracy: 0.9431 - val_loss: 0.3883 - val_binary_accuracy: 0.8857\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3002 - binary_accuracy: 0.9431 - val_loss: 0.3877 - val_binary_accuracy: 0.8857\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2995 - binary_accuracy: 0.9431 - val_loss: 0.3872 - val_binary_accuracy: 0.8857\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2987 - binary_accuracy: 0.9431 - val_loss: 0.3868 - val_binary_accuracy: 0.8857\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2979 - binary_accuracy: 0.9431 - val_loss: 0.3865 - val_binary_accuracy: 0.8762\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2972 - binary_accuracy: 0.9431 - val_loss: 0.3860 - val_binary_accuracy: 0.8762\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2964 - binary_accuracy: 0.9431 - val_loss: 0.3855 - val_binary_accuracy: 0.8762\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2957 - binary_accuracy: 0.9431 - val_loss: 0.3849 - val_binary_accuracy: 0.8762\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2949 - binary_accuracy: 0.9431 - val_loss: 0.3842 - val_binary_accuracy: 0.8762\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.2942 - binary_accuracy: 0.9431 - val_loss: 0.3835 - val_binary_accuracy: 0.8857\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2934 - binary_accuracy: 0.9431 - val_loss: 0.3830 - val_binary_accuracy: 0.8857\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2927 - binary_accuracy: 0.9431 - val_loss: 0.3826 - val_binary_accuracy: 0.8857\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2920 - binary_accuracy: 0.9431 - val_loss: 0.3823 - val_binary_accuracy: 0.8762\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2912 - binary_accuracy: 0.9472 - val_loss: 0.3820 - val_binary_accuracy: 0.8762\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2905 - binary_accuracy: 0.9472 - val_loss: 0.3816 - val_binary_accuracy: 0.8762\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2898 - binary_accuracy: 0.9472 - val_loss: 0.3809 - val_binary_accuracy: 0.8762\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2890 - binary_accuracy: 0.9472 - val_loss: 0.3803 - val_binary_accuracy: 0.8762\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2883 - binary_accuracy: 0.9472 - val_loss: 0.3797 - val_binary_accuracy: 0.8762\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2876 - binary_accuracy: 0.9472 - val_loss: 0.3792 - val_binary_accuracy: 0.8762\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2869 - binary_accuracy: 0.9472 - val_loss: 0.3787 - val_binary_accuracy: 0.8762\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2862 - binary_accuracy: 0.9472 - val_loss: 0.3782 - val_binary_accuracy: 0.8762\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2855 - binary_accuracy: 0.9472 - val_loss: 0.3778 - val_binary_accuracy: 0.8762\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2847 - binary_accuracy: 0.9472 - val_loss: 0.3773 - val_binary_accuracy: 0.8762\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2840 - binary_accuracy: 0.9512 - val_loss: 0.3768 - val_binary_accuracy: 0.8762\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2833 - binary_accuracy: 0.9512 - val_loss: 0.3763 - val_binary_accuracy: 0.8762\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2826 - binary_accuracy: 0.9512 - val_loss: 0.3758 - val_binary_accuracy: 0.8762\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2819 - binary_accuracy: 0.9512 - val_loss: 0.3753 - val_binary_accuracy: 0.8857\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2812 - binary_accuracy: 0.9512 - val_loss: 0.3747 - val_binary_accuracy: 0.8857\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2805 - binary_accuracy: 0.9512 - val_loss: 0.3742 - val_binary_accuracy: 0.8857\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2798 - binary_accuracy: 0.9512 - val_loss: 0.3737 - val_binary_accuracy: 0.8762\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2792 - binary_accuracy: 0.9512 - val_loss: 0.3732 - val_binary_accuracy: 0.8762\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2785 - binary_accuracy: 0.9512 - val_loss: 0.3726 - val_binary_accuracy: 0.8762\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2778 - binary_accuracy: 0.9512 - val_loss: 0.3720 - val_binary_accuracy: 0.8762\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2771 - binary_accuracy: 0.9512 - val_loss: 0.3714 - val_binary_accuracy: 0.8762\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2764 - binary_accuracy: 0.9512 - val_loss: 0.3708 - val_binary_accuracy: 0.8762\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2758 - binary_accuracy: 0.9512 - val_loss: 0.3701 - val_binary_accuracy: 0.8857\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2751 - binary_accuracy: 0.9512 - val_loss: 0.3695 - val_binary_accuracy: 0.8857\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2744 - binary_accuracy: 0.9512 - val_loss: 0.3689 - val_binary_accuracy: 0.8952\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.2738 - binary_accuracy: 0.9512 - val_loss: 0.3684 - val_binary_accuracy: 0.8952\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2731 - binary_accuracy: 0.9512 - val_loss: 0.3679 - val_binary_accuracy: 0.8952\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2725 - binary_accuracy: 0.9512 - val_loss: 0.3675 - val_binary_accuracy: 0.8952\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2718 - binary_accuracy: 0.9512 - val_loss: 0.3671 - val_binary_accuracy: 0.8857\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2711 - binary_accuracy: 0.9512 - val_loss: 0.3666 - val_binary_accuracy: 0.8857\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2705 - binary_accuracy: 0.9512 - val_loss: 0.3662 - val_binary_accuracy: 0.8857\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2698 - binary_accuracy: 0.9512 - val_loss: 0.3658 - val_binary_accuracy: 0.8857\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2692 - binary_accuracy: 0.9512 - val_loss: 0.3653 - val_binary_accuracy: 0.8857\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2686 - binary_accuracy: 0.9512 - val_loss: 0.3648 - val_binary_accuracy: 0.8857\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2679 - binary_accuracy: 0.9512 - val_loss: 0.3642 - val_binary_accuracy: 0.8857\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2673 - binary_accuracy: 0.9512 - val_loss: 0.3638 - val_binary_accuracy: 0.8857\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2667 - binary_accuracy: 0.9512 - val_loss: 0.3634 - val_binary_accuracy: 0.8857\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2660 - binary_accuracy: 0.9512 - val_loss: 0.3631 - val_binary_accuracy: 0.8857\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2654 - binary_accuracy: 0.9512 - val_loss: 0.3627 - val_binary_accuracy: 0.8857\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2648 - binary_accuracy: 0.9512 - val_loss: 0.3622 - val_binary_accuracy: 0.8857\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2642 - binary_accuracy: 0.9512 - val_loss: 0.3618 - val_binary_accuracy: 0.8857\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2635 - binary_accuracy: 0.9512 - val_loss: 0.3614 - val_binary_accuracy: 0.8857\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2629 - binary_accuracy: 0.9512 - val_loss: 0.3611 - val_binary_accuracy: 0.8857\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2623 - binary_accuracy: 0.9512 - val_loss: 0.3606 - val_binary_accuracy: 0.8857\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2617 - binary_accuracy: 0.9512 - val_loss: 0.3603 - val_binary_accuracy: 0.8857\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2611 - binary_accuracy: 0.9512 - val_loss: 0.3598 - val_binary_accuracy: 0.9048\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2605 - binary_accuracy: 0.9512 - val_loss: 0.3594 - val_binary_accuracy: 0.9048\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.2599 - binary_accuracy: 0.9512 - val_loss: 0.3589 - val_binary_accuracy: 0.9048\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2593 - binary_accuracy: 0.9512 - val_loss: 0.3584 - val_binary_accuracy: 0.9048\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2586 - binary_accuracy: 0.9512 - val_loss: 0.3578 - val_binary_accuracy: 0.9048\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2580 - binary_accuracy: 0.9553 - val_loss: 0.3572 - val_binary_accuracy: 0.9048\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2574 - binary_accuracy: 0.9553 - val_loss: 0.3566 - val_binary_accuracy: 0.9048\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2568 - binary_accuracy: 0.9553 - val_loss: 0.3561 - val_binary_accuracy: 0.9048\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2562 - binary_accuracy: 0.9553 - val_loss: 0.3557 - val_binary_accuracy: 0.9048\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2556 - binary_accuracy: 0.9553 - val_loss: 0.3554 - val_binary_accuracy: 0.9048\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2550 - binary_accuracy: 0.9553 - val_loss: 0.3551 - val_binary_accuracy: 0.9048\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2544 - binary_accuracy: 0.9553 - val_loss: 0.3548 - val_binary_accuracy: 0.9048\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2538 - binary_accuracy: 0.9553 - val_loss: 0.3544 - val_binary_accuracy: 0.9048\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2532 - binary_accuracy: 0.9553 - val_loss: 0.3539 - val_binary_accuracy: 0.9048\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2526 - binary_accuracy: 0.9553 - val_loss: 0.3534 - val_binary_accuracy: 0.9048\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2520 - binary_accuracy: 0.9553 - val_loss: 0.3528 - val_binary_accuracy: 0.9048\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2514 - binary_accuracy: 0.9553 - val_loss: 0.3524 - val_binary_accuracy: 0.9048\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2508 - binary_accuracy: 0.9553 - val_loss: 0.3521 - val_binary_accuracy: 0.9048\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2502 - binary_accuracy: 0.9553 - val_loss: 0.3518 - val_binary_accuracy: 0.9048\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2497 - binary_accuracy: 0.9553 - val_loss: 0.3514 - val_binary_accuracy: 0.9048\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2491 - binary_accuracy: 0.9553 - val_loss: 0.3511 - val_binary_accuracy: 0.9048\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2485 - binary_accuracy: 0.9553 - val_loss: 0.3507 - val_binary_accuracy: 0.9048\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2479 - binary_accuracy: 0.9593 - val_loss: 0.3502 - val_binary_accuracy: 0.9048\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2473 - binary_accuracy: 0.9593 - val_loss: 0.3498 - val_binary_accuracy: 0.9048\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2468 - binary_accuracy: 0.9593 - val_loss: 0.3496 - val_binary_accuracy: 0.9048\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2462 - binary_accuracy: 0.9593 - val_loss: 0.3492 - val_binary_accuracy: 0.9048\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2456 - binary_accuracy: 0.9593 - val_loss: 0.3486 - val_binary_accuracy: 0.9048\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2451 - binary_accuracy: 0.9593 - val_loss: 0.3482 - val_binary_accuracy: 0.9048\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2445 - binary_accuracy: 0.9593 - val_loss: 0.3479 - val_binary_accuracy: 0.9048\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2439 - binary_accuracy: 0.9593 - val_loss: 0.3478 - val_binary_accuracy: 0.9048\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2434 - binary_accuracy: 0.9593 - val_loss: 0.3474 - val_binary_accuracy: 0.9048\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2428 - binary_accuracy: 0.9593 - val_loss: 0.3468 - val_binary_accuracy: 0.9048\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2423 - binary_accuracy: 0.9593 - val_loss: 0.3462 - val_binary_accuracy: 0.9048\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2417 - binary_accuracy: 0.9593 - val_loss: 0.3457 - val_binary_accuracy: 0.9048\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2412 - binary_accuracy: 0.9593 - val_loss: 0.3454 - val_binary_accuracy: 0.9048\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2406 - binary_accuracy: 0.9593 - val_loss: 0.3452 - val_binary_accuracy: 0.9048\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2401 - binary_accuracy: 0.9593 - val_loss: 0.3450 - val_binary_accuracy: 0.9048\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2395 - binary_accuracy: 0.9593 - val_loss: 0.3446 - val_binary_accuracy: 0.9048\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2390 - binary_accuracy: 0.9593 - val_loss: 0.3440 - val_binary_accuracy: 0.9048\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2384 - binary_accuracy: 0.9593 - val_loss: 0.3434 - val_binary_accuracy: 0.9048\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2379 - binary_accuracy: 0.9593 - val_loss: 0.3432 - val_binary_accuracy: 0.9048\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2374 - binary_accuracy: 0.9593 - val_loss: 0.3431 - val_binary_accuracy: 0.9048\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2368 - binary_accuracy: 0.9593 - val_loss: 0.3430 - val_binary_accuracy: 0.9048\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2363 - binary_accuracy: 0.9593 - val_loss: 0.3425 - val_binary_accuracy: 0.9048\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2358 - binary_accuracy: 0.9593 - val_loss: 0.3420 - val_binary_accuracy: 0.9048\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.2353 - binary_accuracy: 0.9593 - val_loss: 0.3417 - val_binary_accuracy: 0.9048\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2348 - binary_accuracy: 0.9593 - val_loss: 0.3416 - val_binary_accuracy: 0.9048\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.2342 - binary_accuracy: 0.9593 - val_loss: 0.3416 - val_binary_accuracy: 0.8952\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2337 - binary_accuracy: 0.9593 - val_loss: 0.3412 - val_binary_accuracy: 0.8952\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2332 - binary_accuracy: 0.9593 - val_loss: 0.3406 - val_binary_accuracy: 0.9048\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2327 - binary_accuracy: 0.9593 - val_loss: 0.3401 - val_binary_accuracy: 0.9048\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2322 - binary_accuracy: 0.9593 - val_loss: 0.3399 - val_binary_accuracy: 0.9048\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2317 - binary_accuracy: 0.9593 - val_loss: 0.3397 - val_binary_accuracy: 0.9048\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2312 - binary_accuracy: 0.9593 - val_loss: 0.3393 - val_binary_accuracy: 0.9048\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2307 - binary_accuracy: 0.9593 - val_loss: 0.3391 - val_binary_accuracy: 0.9048\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2302 - binary_accuracy: 0.9593 - val_loss: 0.3388 - val_binary_accuracy: 0.9048\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2297 - binary_accuracy: 0.9593 - val_loss: 0.3384 - val_binary_accuracy: 0.9048\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2292 - binary_accuracy: 0.9593 - val_loss: 0.3381 - val_binary_accuracy: 0.9143\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2287 - binary_accuracy: 0.9593 - val_loss: 0.3381 - val_binary_accuracy: 0.9048\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2282 - binary_accuracy: 0.9593 - val_loss: 0.3378 - val_binary_accuracy: 0.9048\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2277 - binary_accuracy: 0.9593 - val_loss: 0.3372 - val_binary_accuracy: 0.9048\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2272 - binary_accuracy: 0.9593 - val_loss: 0.3369 - val_binary_accuracy: 0.9048\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2267 - binary_accuracy: 0.9593 - val_loss: 0.3367 - val_binary_accuracy: 0.9048\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2262 - binary_accuracy: 0.9593 - val_loss: 0.3365 - val_binary_accuracy: 0.9048\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2258 - binary_accuracy: 0.9593 - val_loss: 0.3360 - val_binary_accuracy: 0.9048\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2253 - binary_accuracy: 0.9593 - val_loss: 0.3356 - val_binary_accuracy: 0.9143\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2248 - binary_accuracy: 0.9593 - val_loss: 0.3353 - val_binary_accuracy: 0.9143\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2243 - binary_accuracy: 0.9593 - val_loss: 0.3351 - val_binary_accuracy: 0.9048\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2238 - binary_accuracy: 0.9634 - val_loss: 0.3349 - val_binary_accuracy: 0.9048\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2234 - binary_accuracy: 0.9634 - val_loss: 0.3347 - val_binary_accuracy: 0.9048\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2229 - binary_accuracy: 0.9634 - val_loss: 0.3343 - val_binary_accuracy: 0.9048\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2224 - binary_accuracy: 0.9634 - val_loss: 0.3339 - val_binary_accuracy: 0.9048\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2220 - binary_accuracy: 0.9634 - val_loss: 0.3337 - val_binary_accuracy: 0.9048\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2215 - binary_accuracy: 0.9634 - val_loss: 0.3335 - val_binary_accuracy: 0.9048\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2210 - binary_accuracy: 0.9634 - val_loss: 0.3332 - val_binary_accuracy: 0.9048\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2206 - binary_accuracy: 0.9634 - val_loss: 0.3328 - val_binary_accuracy: 0.9048\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2201 - binary_accuracy: 0.9634 - val_loss: 0.3326 - val_binary_accuracy: 0.9048\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2197 - binary_accuracy: 0.9634 - val_loss: 0.3324 - val_binary_accuracy: 0.9048\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2192 - binary_accuracy: 0.9634 - val_loss: 0.3322 - val_binary_accuracy: 0.9048\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2187 - binary_accuracy: 0.9634 - val_loss: 0.3319 - val_binary_accuracy: 0.9048\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2183 - binary_accuracy: 0.9634 - val_loss: 0.3316 - val_binary_accuracy: 0.9048\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.2178 - binary_accuracy: 0.9634 - val_loss: 0.3314 - val_binary_accuracy: 0.9048\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2174 - binary_accuracy: 0.9634 - val_loss: 0.3310 - val_binary_accuracy: 0.9048\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2169 - binary_accuracy: 0.9634 - val_loss: 0.3307 - val_binary_accuracy: 0.9048\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2165 - binary_accuracy: 0.9634 - val_loss: 0.3305 - val_binary_accuracy: 0.8952\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2160 - binary_accuracy: 0.9634 - val_loss: 0.3301 - val_binary_accuracy: 0.9048\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2156 - binary_accuracy: 0.9634 - val_loss: 0.3298 - val_binary_accuracy: 0.9048\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2152 - binary_accuracy: 0.9634 - val_loss: 0.3297 - val_binary_accuracy: 0.9048\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2147 - binary_accuracy: 0.9634 - val_loss: 0.3294 - val_binary_accuracy: 0.9048\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2143 - binary_accuracy: 0.9634 - val_loss: 0.3288 - val_binary_accuracy: 0.9048\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2138 - binary_accuracy: 0.9634 - val_loss: 0.3286 - val_binary_accuracy: 0.9143\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2134 - binary_accuracy: 0.9634 - val_loss: 0.3286 - val_binary_accuracy: 0.9048\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2130 - binary_accuracy: 0.9634 - val_loss: 0.3282 - val_binary_accuracy: 0.9048\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2125 - binary_accuracy: 0.9634 - val_loss: 0.3279 - val_binary_accuracy: 0.9143\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2121 - binary_accuracy: 0.9634 - val_loss: 0.3276 - val_binary_accuracy: 0.9048\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2117 - binary_accuracy: 0.9634 - val_loss: 0.3273 - val_binary_accuracy: 0.9048\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2112 - binary_accuracy: 0.9634 - val_loss: 0.3270 - val_binary_accuracy: 0.9048\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2108 - binary_accuracy: 0.9634 - val_loss: 0.3267 - val_binary_accuracy: 0.9048\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2104 - binary_accuracy: 0.9634 - val_loss: 0.3266 - val_binary_accuracy: 0.9143\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2100 - binary_accuracy: 0.9634 - val_loss: 0.3263 - val_binary_accuracy: 0.9143\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2095 - binary_accuracy: 0.9634 - val_loss: 0.3260 - val_binary_accuracy: 0.9143\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.2091 - binary_accuracy: 0.9634 - val_loss: 0.3256 - val_binary_accuracy: 0.9143\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.2087 - binary_accuracy: 0.9675 - val_loss: 0.3254 - val_binary_accuracy: 0.9143\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2083 - binary_accuracy: 0.9675 - val_loss: 0.3252 - val_binary_accuracy: 0.9143\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2079 - binary_accuracy: 0.9634 - val_loss: 0.3250 - val_binary_accuracy: 0.9143\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2075 - binary_accuracy: 0.9634 - val_loss: 0.3247 - val_binary_accuracy: 0.9143\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2071 - binary_accuracy: 0.9675 - val_loss: 0.3242 - val_binary_accuracy: 0.9143\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2066 - binary_accuracy: 0.9675 - val_loss: 0.3240 - val_binary_accuracy: 0.9143\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2062 - binary_accuracy: 0.9675 - val_loss: 0.3240 - val_binary_accuracy: 0.9143\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2058 - binary_accuracy: 0.9675 - val_loss: 0.3237 - val_binary_accuracy: 0.9143\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2054 - binary_accuracy: 0.9675 - val_loss: 0.3233 - val_binary_accuracy: 0.9048\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.2050 - binary_accuracy: 0.9715 - val_loss: 0.3231 - val_binary_accuracy: 0.9048\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2046 - binary_accuracy: 0.9756 - val_loss: 0.3229 - val_binary_accuracy: 0.9048\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2042 - binary_accuracy: 0.9756 - val_loss: 0.3227 - val_binary_accuracy: 0.9048\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2038 - binary_accuracy: 0.9756 - val_loss: 0.3224 - val_binary_accuracy: 0.9048\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2034 - binary_accuracy: 0.9756 - val_loss: 0.3220 - val_binary_accuracy: 0.9048\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2030 - binary_accuracy: 0.9756 - val_loss: 0.3219 - val_binary_accuracy: 0.9048\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2026 - binary_accuracy: 0.9756 - val_loss: 0.3216 - val_binary_accuracy: 0.9048\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2022 - binary_accuracy: 0.9756 - val_loss: 0.3213 - val_binary_accuracy: 0.9048\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2019 - binary_accuracy: 0.9756 - val_loss: 0.3209 - val_binary_accuracy: 0.9048\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2015 - binary_accuracy: 0.9756 - val_loss: 0.3208 - val_binary_accuracy: 0.9048\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2011 - binary_accuracy: 0.9756 - val_loss: 0.3208 - val_binary_accuracy: 0.9048\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2007 - binary_accuracy: 0.9756 - val_loss: 0.3206 - val_binary_accuracy: 0.9048\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2003 - binary_accuracy: 0.9756 - val_loss: 0.3200 - val_binary_accuracy: 0.9048\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1999 - binary_accuracy: 0.9756 - val_loss: 0.3196 - val_binary_accuracy: 0.9048\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1995 - binary_accuracy: 0.9756 - val_loss: 0.3195 - val_binary_accuracy: 0.9048\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1992 - binary_accuracy: 0.9756 - val_loss: 0.3195 - val_binary_accuracy: 0.9048\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1988 - binary_accuracy: 0.9756 - val_loss: 0.3193 - val_binary_accuracy: 0.9048\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1984 - binary_accuracy: 0.9756 - val_loss: 0.3188 - val_binary_accuracy: 0.9048\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1980 - binary_accuracy: 0.9756 - val_loss: 0.3182 - val_binary_accuracy: 0.9048\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1977 - binary_accuracy: 0.9756 - val_loss: 0.3179 - val_binary_accuracy: 0.9048\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1973 - binary_accuracy: 0.9756 - val_loss: 0.3180 - val_binary_accuracy: 0.9048\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1969 - binary_accuracy: 0.9756 - val_loss: 0.3180 - val_binary_accuracy: 0.9048\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1965 - binary_accuracy: 0.9756 - val_loss: 0.3179 - val_binary_accuracy: 0.9143\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1962 - binary_accuracy: 0.9756 - val_loss: 0.3176 - val_binary_accuracy: 0.9048\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1958 - binary_accuracy: 0.9756 - val_loss: 0.3171 - val_binary_accuracy: 0.9048\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1954 - binary_accuracy: 0.9756 - val_loss: 0.3166 - val_binary_accuracy: 0.9048\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1951 - binary_accuracy: 0.9756 - val_loss: 0.3164 - val_binary_accuracy: 0.9143\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1947 - binary_accuracy: 0.9756 - val_loss: 0.3164 - val_binary_accuracy: 0.9143\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1943 - binary_accuracy: 0.9756 - val_loss: 0.3164 - val_binary_accuracy: 0.9143\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1940 - binary_accuracy: 0.9756 - val_loss: 0.3162 - val_binary_accuracy: 0.9143\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1936 - binary_accuracy: 0.9756 - val_loss: 0.3158 - val_binary_accuracy: 0.9143\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1933 - binary_accuracy: 0.9756 - val_loss: 0.3154 - val_binary_accuracy: 0.9143\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1929 - binary_accuracy: 0.9756 - val_loss: 0.3151 - val_binary_accuracy: 0.9143\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1926 - binary_accuracy: 0.9756 - val_loss: 0.3149 - val_binary_accuracy: 0.9143\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1922 - binary_accuracy: 0.9756 - val_loss: 0.3149 - val_binary_accuracy: 0.9143\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1919 - binary_accuracy: 0.9756 - val_loss: 0.3148 - val_binary_accuracy: 0.9143\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1915 - binary_accuracy: 0.9756 - val_loss: 0.3144 - val_binary_accuracy: 0.9143\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1912 - binary_accuracy: 0.9756 - val_loss: 0.3140 - val_binary_accuracy: 0.9143\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1908 - binary_accuracy: 0.9756 - val_loss: 0.3137 - val_binary_accuracy: 0.9143\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1905 - binary_accuracy: 0.9756 - val_loss: 0.3136 - val_binary_accuracy: 0.9143\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1901 - binary_accuracy: 0.9756 - val_loss: 0.3135 - val_binary_accuracy: 0.9143\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1898 - binary_accuracy: 0.9756 - val_loss: 0.3132 - val_binary_accuracy: 0.9143\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1894 - binary_accuracy: 0.9756 - val_loss: 0.3129 - val_binary_accuracy: 0.9143\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1891 - binary_accuracy: 0.9756 - val_loss: 0.3126 - val_binary_accuracy: 0.9143\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1888 - binary_accuracy: 0.9756 - val_loss: 0.3123 - val_binary_accuracy: 0.9143\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1884 - binary_accuracy: 0.9756 - val_loss: 0.3121 - val_binary_accuracy: 0.9143\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1881 - binary_accuracy: 0.9756 - val_loss: 0.3120 - val_binary_accuracy: 0.9143\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1877 - binary_accuracy: 0.9756 - val_loss: 0.3118 - val_binary_accuracy: 0.9143\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1874 - binary_accuracy: 0.9756 - val_loss: 0.3116 - val_binary_accuracy: 0.9143\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1871 - binary_accuracy: 0.9756 - val_loss: 0.3113 - val_binary_accuracy: 0.9143\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1867 - binary_accuracy: 0.9756 - val_loss: 0.3110 - val_binary_accuracy: 0.9143\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1864 - binary_accuracy: 0.9756 - val_loss: 0.3107 - val_binary_accuracy: 0.9143\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1861 - binary_accuracy: 0.9756 - val_loss: 0.3106 - val_binary_accuracy: 0.9143\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1857 - binary_accuracy: 0.9756 - val_loss: 0.3105 - val_binary_accuracy: 0.9143\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1854 - binary_accuracy: 0.9756 - val_loss: 0.3103 - val_binary_accuracy: 0.9143\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1851 - binary_accuracy: 0.9756 - val_loss: 0.3100 - val_binary_accuracy: 0.9143\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1848 - binary_accuracy: 0.9756 - val_loss: 0.3096 - val_binary_accuracy: 0.9143\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1844 - binary_accuracy: 0.9756 - val_loss: 0.3094 - val_binary_accuracy: 0.9143\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1841 - binary_accuracy: 0.9756 - val_loss: 0.3092 - val_binary_accuracy: 0.9143\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1838 - binary_accuracy: 0.9756 - val_loss: 0.3090 - val_binary_accuracy: 0.9143\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.1835 - binary_accuracy: 0.9756 - val_loss: 0.3087 - val_binary_accuracy: 0.9143\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1831 - binary_accuracy: 0.9756 - val_loss: 0.3085 - val_binary_accuracy: 0.9143\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1828 - binary_accuracy: 0.9756 - val_loss: 0.3083 - val_binary_accuracy: 0.9143\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1825 - binary_accuracy: 0.9756 - val_loss: 0.3081 - val_binary_accuracy: 0.9143\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1822 - binary_accuracy: 0.9756 - val_loss: 0.3080 - val_binary_accuracy: 0.9143\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1819 - binary_accuracy: 0.9756 - val_loss: 0.3078 - val_binary_accuracy: 0.9143\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1816 - binary_accuracy: 0.9756 - val_loss: 0.3075 - val_binary_accuracy: 0.9143\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1812 - binary_accuracy: 0.9756 - val_loss: 0.3072 - val_binary_accuracy: 0.9143\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1809 - binary_accuracy: 0.9756 - val_loss: 0.3069 - val_binary_accuracy: 0.9143\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1806 - binary_accuracy: 0.9756 - val_loss: 0.3067 - val_binary_accuracy: 0.9143\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1803 - binary_accuracy: 0.9756 - val_loss: 0.3066 - val_binary_accuracy: 0.9143\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1800 - binary_accuracy: 0.9756 - val_loss: 0.3065 - val_binary_accuracy: 0.9143\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1797 - binary_accuracy: 0.9756 - val_loss: 0.3063 - val_binary_accuracy: 0.9143\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1794 - binary_accuracy: 0.9756 - val_loss: 0.3060 - val_binary_accuracy: 0.9143\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1791 - binary_accuracy: 0.9756 - val_loss: 0.3057 - val_binary_accuracy: 0.9143\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1788 - binary_accuracy: 0.9756 - val_loss: 0.3055 - val_binary_accuracy: 0.9143\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1785 - binary_accuracy: 0.9756 - val_loss: 0.3054 - val_binary_accuracy: 0.9143\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1782 - binary_accuracy: 0.9756 - val_loss: 0.3053 - val_binary_accuracy: 0.9143\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1779 - binary_accuracy: 0.9756 - val_loss: 0.3050 - val_binary_accuracy: 0.9143\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1776 - binary_accuracy: 0.9756 - val_loss: 0.3047 - val_binary_accuracy: 0.9143\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1773 - binary_accuracy: 0.9756 - val_loss: 0.3044 - val_binary_accuracy: 0.9143\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1770 - binary_accuracy: 0.9756 - val_loss: 0.3044 - val_binary_accuracy: 0.9143\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1767 - binary_accuracy: 0.9756 - val_loss: 0.3044 - val_binary_accuracy: 0.9143\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1764 - binary_accuracy: 0.9756 - val_loss: 0.3042 - val_binary_accuracy: 0.9143\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1761 - binary_accuracy: 0.9756 - val_loss: 0.3038 - val_binary_accuracy: 0.9143\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1758 - binary_accuracy: 0.9756 - val_loss: 0.3035 - val_binary_accuracy: 0.9143\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1755 - binary_accuracy: 0.9756 - val_loss: 0.3033 - val_binary_accuracy: 0.9143\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1752 - binary_accuracy: 0.9756 - val_loss: 0.3031 - val_binary_accuracy: 0.9143\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1749 - binary_accuracy: 0.9756 - val_loss: 0.3030 - val_binary_accuracy: 0.9143\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1746 - binary_accuracy: 0.9756 - val_loss: 0.3029 - val_binary_accuracy: 0.9143\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1743 - binary_accuracy: 0.9756 - val_loss: 0.3027 - val_binary_accuracy: 0.9143\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1740 - binary_accuracy: 0.9756 - val_loss: 0.3024 - val_binary_accuracy: 0.9143\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1737 - binary_accuracy: 0.9756 - val_loss: 0.3021 - val_binary_accuracy: 0.9143\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1734 - binary_accuracy: 0.9756 - val_loss: 0.3020 - val_binary_accuracy: 0.9143\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1732 - binary_accuracy: 0.9756 - val_loss: 0.3019 - val_binary_accuracy: 0.9143\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1729 - binary_accuracy: 0.9756 - val_loss: 0.3017 - val_binary_accuracy: 0.9143\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1726 - binary_accuracy: 0.9756 - val_loss: 0.3015 - val_binary_accuracy: 0.9143\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1723 - binary_accuracy: 0.9756 - val_loss: 0.3013 - val_binary_accuracy: 0.9143\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1720 - binary_accuracy: 0.9756 - val_loss: 0.3012 - val_binary_accuracy: 0.9143\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1717 - binary_accuracy: 0.9756 - val_loss: 0.3012 - val_binary_accuracy: 0.9143\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1715 - binary_accuracy: 0.9756 - val_loss: 0.3010 - val_binary_accuracy: 0.9143\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1712 - binary_accuracy: 0.9756 - val_loss: 0.3007 - val_binary_accuracy: 0.9143\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1709 - binary_accuracy: 0.9756 - val_loss: 0.3005 - val_binary_accuracy: 0.9143\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1706 - binary_accuracy: 0.9756 - val_loss: 0.3003 - val_binary_accuracy: 0.9143\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1704 - binary_accuracy: 0.9756 - val_loss: 0.3003 - val_binary_accuracy: 0.9143\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1701 - binary_accuracy: 0.9756 - val_loss: 0.3003 - val_binary_accuracy: 0.9143\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1698 - binary_accuracy: 0.9756 - val_loss: 0.3000 - val_binary_accuracy: 0.9143\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1695 - binary_accuracy: 0.9756 - val_loss: 0.2998 - val_binary_accuracy: 0.9143\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1693 - binary_accuracy: 0.9756 - val_loss: 0.2995 - val_binary_accuracy: 0.9143\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1690 - binary_accuracy: 0.9756 - val_loss: 0.2993 - val_binary_accuracy: 0.9143\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1687 - binary_accuracy: 0.9756 - val_loss: 0.2992 - val_binary_accuracy: 0.9143\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1684 - binary_accuracy: 0.9756 - val_loss: 0.2991 - val_binary_accuracy: 0.9143\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1682 - binary_accuracy: 0.9756 - val_loss: 0.2989 - val_binary_accuracy: 0.9143\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1679 - binary_accuracy: 0.9756 - val_loss: 0.2987 - val_binary_accuracy: 0.9143\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1676 - binary_accuracy: 0.9756 - val_loss: 0.2985 - val_binary_accuracy: 0.9143\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1674 - binary_accuracy: 0.9756 - val_loss: 0.2983 - val_binary_accuracy: 0.9143\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1671 - binary_accuracy: 0.9756 - val_loss: 0.2982 - val_binary_accuracy: 0.9143\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1668 - binary_accuracy: 0.9756 - val_loss: 0.2981 - val_binary_accuracy: 0.9143\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1666 - binary_accuracy: 0.9756 - val_loss: 0.2980 - val_binary_accuracy: 0.9143\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1663 - binary_accuracy: 0.9756 - val_loss: 0.2978 - val_binary_accuracy: 0.9143\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1660 - binary_accuracy: 0.9756 - val_loss: 0.2977 - val_binary_accuracy: 0.9143\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1658 - binary_accuracy: 0.9756 - val_loss: 0.2975 - val_binary_accuracy: 0.9143\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1655 - binary_accuracy: 0.9756 - val_loss: 0.2972 - val_binary_accuracy: 0.9143\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1653 - binary_accuracy: 0.9756 - val_loss: 0.2971 - val_binary_accuracy: 0.9143\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1650 - binary_accuracy: 0.9756 - val_loss: 0.2970 - val_binary_accuracy: 0.9143\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1647 - binary_accuracy: 0.9756 - val_loss: 0.2969 - val_binary_accuracy: 0.9143\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1645 - binary_accuracy: 0.9756 - val_loss: 0.2968 - val_binary_accuracy: 0.9143\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1642 - binary_accuracy: 0.9756 - val_loss: 0.2966 - val_binary_accuracy: 0.9143\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1640 - binary_accuracy: 0.9756 - val_loss: 0.2964 - val_binary_accuracy: 0.9143\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1637 - binary_accuracy: 0.9756 - val_loss: 0.2962 - val_binary_accuracy: 0.9143\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1635 - binary_accuracy: 0.9756 - val_loss: 0.2960 - val_binary_accuracy: 0.9143\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1632 - binary_accuracy: 0.9756 - val_loss: 0.2959 - val_binary_accuracy: 0.9143\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1630 - binary_accuracy: 0.9756 - val_loss: 0.2958 - val_binary_accuracy: 0.9143\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1627 - binary_accuracy: 0.9756 - val_loss: 0.2956 - val_binary_accuracy: 0.9143\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1625 - binary_accuracy: 0.9756 - val_loss: 0.2954 - val_binary_accuracy: 0.9143\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1622 - binary_accuracy: 0.9756 - val_loss: 0.2952 - val_binary_accuracy: 0.9143\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1620 - binary_accuracy: 0.9756 - val_loss: 0.2951 - val_binary_accuracy: 0.9143\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1617 - binary_accuracy: 0.9756 - val_loss: 0.2950 - val_binary_accuracy: 0.9143\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1615 - binary_accuracy: 0.9756 - val_loss: 0.2950 - val_binary_accuracy: 0.9143\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1612 - binary_accuracy: 0.9756 - val_loss: 0.2948 - val_binary_accuracy: 0.9143\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1610 - binary_accuracy: 0.9756 - val_loss: 0.2945 - val_binary_accuracy: 0.9143\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1607 - binary_accuracy: 0.9756 - val_loss: 0.2942 - val_binary_accuracy: 0.9143\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1605 - binary_accuracy: 0.9756 - val_loss: 0.2941 - val_binary_accuracy: 0.9143\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1602 - binary_accuracy: 0.9756 - val_loss: 0.2942 - val_binary_accuracy: 0.9143\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1600 - binary_accuracy: 0.9756 - val_loss: 0.2941 - val_binary_accuracy: 0.9143\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1598 - binary_accuracy: 0.9756 - val_loss: 0.2939 - val_binary_accuracy: 0.9143\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1595 - binary_accuracy: 0.9756 - val_loss: 0.2936 - val_binary_accuracy: 0.9143\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1593 - binary_accuracy: 0.9756 - val_loss: 0.2934 - val_binary_accuracy: 0.9143\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1590 - binary_accuracy: 0.9756 - val_loss: 0.2934 - val_binary_accuracy: 0.9143\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1588 - binary_accuracy: 0.9756 - val_loss: 0.2934 - val_binary_accuracy: 0.9143\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1585 - binary_accuracy: 0.9756 - val_loss: 0.2933 - val_binary_accuracy: 0.9143\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1583 - binary_accuracy: 0.9756 - val_loss: 0.2931 - val_binary_accuracy: 0.9143\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1581 - binary_accuracy: 0.9756 - val_loss: 0.2928 - val_binary_accuracy: 0.9143\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1578 - binary_accuracy: 0.9756 - val_loss: 0.2926 - val_binary_accuracy: 0.9143\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1576 - binary_accuracy: 0.9756 - val_loss: 0.2925 - val_binary_accuracy: 0.9143\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1574 - binary_accuracy: 0.9756 - val_loss: 0.2924 - val_binary_accuracy: 0.9143\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1571 - binary_accuracy: 0.9756 - val_loss: 0.2924 - val_binary_accuracy: 0.9143\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1569 - binary_accuracy: 0.9756 - val_loss: 0.2923 - val_binary_accuracy: 0.9143\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1567 - binary_accuracy: 0.9756 - val_loss: 0.2922 - val_binary_accuracy: 0.9143\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1564 - binary_accuracy: 0.9756 - val_loss: 0.2919 - val_binary_accuracy: 0.9143\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1562 - binary_accuracy: 0.9756 - val_loss: 0.2917 - val_binary_accuracy: 0.9143\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1560 - binary_accuracy: 0.9756 - val_loss: 0.2917 - val_binary_accuracy: 0.9143\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1557 - binary_accuracy: 0.9756 - val_loss: 0.2916 - val_binary_accuracy: 0.9143\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1555 - binary_accuracy: 0.9756 - val_loss: 0.2916 - val_binary_accuracy: 0.9143\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1553 - binary_accuracy: 0.9756 - val_loss: 0.2915 - val_binary_accuracy: 0.9143\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.1550 - binary_accuracy: 0.9756 - val_loss: 0.2914 - val_binary_accuracy: 0.9143\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1548 - binary_accuracy: 0.9756 - val_loss: 0.2911 - val_binary_accuracy: 0.9143\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1546 - binary_accuracy: 0.9756 - val_loss: 0.2909 - val_binary_accuracy: 0.9143\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1544 - binary_accuracy: 0.9756 - val_loss: 0.2907 - val_binary_accuracy: 0.9143\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1541 - binary_accuracy: 0.9756 - val_loss: 0.2907 - val_binary_accuracy: 0.9143\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1539 - binary_accuracy: 0.9756 - val_loss: 0.2907 - val_binary_accuracy: 0.9143\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1537 - binary_accuracy: 0.9756 - val_loss: 0.2906 - val_binary_accuracy: 0.9048\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1535 - binary_accuracy: 0.9756 - val_loss: 0.2905 - val_binary_accuracy: 0.9048\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1532 - binary_accuracy: 0.9756 - val_loss: 0.2902 - val_binary_accuracy: 0.9143\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1530 - binary_accuracy: 0.9756 - val_loss: 0.2900 - val_binary_accuracy: 0.9143\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1528 - binary_accuracy: 0.9756 - val_loss: 0.2899 - val_binary_accuracy: 0.9143\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1526 - binary_accuracy: 0.9756 - val_loss: 0.2898 - val_binary_accuracy: 0.9048\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1523 - binary_accuracy: 0.9756 - val_loss: 0.2898 - val_binary_accuracy: 0.9048\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1521 - binary_accuracy: 0.9756 - val_loss: 0.2897 - val_binary_accuracy: 0.9048\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1519 - binary_accuracy: 0.9756 - val_loss: 0.2896 - val_binary_accuracy: 0.9143\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1517 - binary_accuracy: 0.9756 - val_loss: 0.2893 - val_binary_accuracy: 0.9143\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1515 - binary_accuracy: 0.9756 - val_loss: 0.2892 - val_binary_accuracy: 0.9143\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1513 - binary_accuracy: 0.9756 - val_loss: 0.2891 - val_binary_accuracy: 0.9143\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1510 - binary_accuracy: 0.9756 - val_loss: 0.2891 - val_binary_accuracy: 0.9143\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1508 - binary_accuracy: 0.9756 - val_loss: 0.2892 - val_binary_accuracy: 0.9048\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1506 - binary_accuracy: 0.9756 - val_loss: 0.2891 - val_binary_accuracy: 0.9048\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1504 - binary_accuracy: 0.9756 - val_loss: 0.2888 - val_binary_accuracy: 0.9143\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1502 - binary_accuracy: 0.9756 - val_loss: 0.2885 - val_binary_accuracy: 0.9143\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1500 - binary_accuracy: 0.9756 - val_loss: 0.2883 - val_binary_accuracy: 0.9048\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1498 - binary_accuracy: 0.9756 - val_loss: 0.2883 - val_binary_accuracy: 0.9048\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1495 - binary_accuracy: 0.9756 - val_loss: 0.2882 - val_binary_accuracy: 0.9048\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1493 - binary_accuracy: 0.9756 - val_loss: 0.2882 - val_binary_accuracy: 0.8952\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1491 - binary_accuracy: 0.9756 - val_loss: 0.2881 - val_binary_accuracy: 0.8952\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1489 - binary_accuracy: 0.9756 - val_loss: 0.2879 - val_binary_accuracy: 0.9048\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1487 - binary_accuracy: 0.9756 - val_loss: 0.2876 - val_binary_accuracy: 0.9048\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1485 - binary_accuracy: 0.9756 - val_loss: 0.2875 - val_binary_accuracy: 0.9048\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1483 - binary_accuracy: 0.9756 - val_loss: 0.2874 - val_binary_accuracy: 0.9048\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.1481 - binary_accuracy: 0.9756 - val_loss: 0.2874 - val_binary_accuracy: 0.9048\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1479 - binary_accuracy: 0.9756 - val_loss: 0.2874 - val_binary_accuracy: 0.8952\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1477 - binary_accuracy: 0.9756 - val_loss: 0.2872 - val_binary_accuracy: 0.9048\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1474 - binary_accuracy: 0.9756 - val_loss: 0.2870 - val_binary_accuracy: 0.9048\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1472 - binary_accuracy: 0.9756 - val_loss: 0.2868 - val_binary_accuracy: 0.9048\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1470 - binary_accuracy: 0.9756 - val_loss: 0.2867 - val_binary_accuracy: 0.9048\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1468 - binary_accuracy: 0.9756 - val_loss: 0.2867 - val_binary_accuracy: 0.9048\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1466 - binary_accuracy: 0.9756 - val_loss: 0.2865 - val_binary_accuracy: 0.9048\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1464 - binary_accuracy: 0.9756 - val_loss: 0.2864 - val_binary_accuracy: 0.9048\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1462 - binary_accuracy: 0.9756 - val_loss: 0.2864 - val_binary_accuracy: 0.9048\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1460 - binary_accuracy: 0.9756 - val_loss: 0.2862 - val_binary_accuracy: 0.9048\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1458 - binary_accuracy: 0.9756 - val_loss: 0.2861 - val_binary_accuracy: 0.9048\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1456 - binary_accuracy: 0.9756 - val_loss: 0.2860 - val_binary_accuracy: 0.9048\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1454 - binary_accuracy: 0.9756 - val_loss: 0.2859 - val_binary_accuracy: 0.9048\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1452 - binary_accuracy: 0.9756 - val_loss: 0.2858 - val_binary_accuracy: 0.9048\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1450 - binary_accuracy: 0.9756 - val_loss: 0.2857 - val_binary_accuracy: 0.9048\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1448 - binary_accuracy: 0.9756 - val_loss: 0.2856 - val_binary_accuracy: 0.9048\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1446 - binary_accuracy: 0.9756 - val_loss: 0.2855 - val_binary_accuracy: 0.9048\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1444 - binary_accuracy: 0.9756 - val_loss: 0.2854 - val_binary_accuracy: 0.9048\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1442 - binary_accuracy: 0.9756 - val_loss: 0.2853 - val_binary_accuracy: 0.9048\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1440 - binary_accuracy: 0.9756 - val_loss: 0.2852 - val_binary_accuracy: 0.9048\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1438 - binary_accuracy: 0.9756 - val_loss: 0.2851 - val_binary_accuracy: 0.9048\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1436 - binary_accuracy: 0.9756 - val_loss: 0.2850 - val_binary_accuracy: 0.9048\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1434 - binary_accuracy: 0.9756 - val_loss: 0.2849 - val_binary_accuracy: 0.9048\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1432 - binary_accuracy: 0.9756 - val_loss: 0.2848 - val_binary_accuracy: 0.9048\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1430 - binary_accuracy: 0.9756 - val_loss: 0.2847 - val_binary_accuracy: 0.9048\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1429 - binary_accuracy: 0.9756 - val_loss: 0.2847 - val_binary_accuracy: 0.9048\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1427 - binary_accuracy: 0.9756 - val_loss: 0.2845 - val_binary_accuracy: 0.9048\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1425 - binary_accuracy: 0.9756 - val_loss: 0.2844 - val_binary_accuracy: 0.9048\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1423 - binary_accuracy: 0.9756 - val_loss: 0.2843 - val_binary_accuracy: 0.9048\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1421 - binary_accuracy: 0.9756 - val_loss: 0.2842 - val_binary_accuracy: 0.9048\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1419 - binary_accuracy: 0.9756 - val_loss: 0.2840 - val_binary_accuracy: 0.9048\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1417 - binary_accuracy: 0.9756 - val_loss: 0.2840 - val_binary_accuracy: 0.9048\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1415 - binary_accuracy: 0.9756 - val_loss: 0.2840 - val_binary_accuracy: 0.9048\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1413 - binary_accuracy: 0.9756 - val_loss: 0.2839 - val_binary_accuracy: 0.9048\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1411 - binary_accuracy: 0.9756 - val_loss: 0.2838 - val_binary_accuracy: 0.9048\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1409 - binary_accuracy: 0.9756 - val_loss: 0.2836 - val_binary_accuracy: 0.9048\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1407 - binary_accuracy: 0.9756 - val_loss: 0.2834 - val_binary_accuracy: 0.9048\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1405 - binary_accuracy: 0.9756 - val_loss: 0.2833 - val_binary_accuracy: 0.9048\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1403 - binary_accuracy: 0.9756 - val_loss: 0.2833 - val_binary_accuracy: 0.9048\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1401 - binary_accuracy: 0.9756 - val_loss: 0.2832 - val_binary_accuracy: 0.9048\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1400 - binary_accuracy: 0.9756 - val_loss: 0.2830 - val_binary_accuracy: 0.9048\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1398 - binary_accuracy: 0.9756 - val_loss: 0.2829 - val_binary_accuracy: 0.9048\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1396 - binary_accuracy: 0.9756 - val_loss: 0.2829 - val_binary_accuracy: 0.9048\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1394 - binary_accuracy: 0.9756 - val_loss: 0.2829 - val_binary_accuracy: 0.9048\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1392 - binary_accuracy: 0.9756 - val_loss: 0.2829 - val_binary_accuracy: 0.9048\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1390 - binary_accuracy: 0.9756 - val_loss: 0.2828 - val_binary_accuracy: 0.9048\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1388 - binary_accuracy: 0.9756 - val_loss: 0.2826 - val_binary_accuracy: 0.9048\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1386 - binary_accuracy: 0.9756 - val_loss: 0.2824 - val_binary_accuracy: 0.9048\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1385 - binary_accuracy: 0.9756 - val_loss: 0.2824 - val_binary_accuracy: 0.9048\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1383 - binary_accuracy: 0.9756 - val_loss: 0.2824 - val_binary_accuracy: 0.9048\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1381 - binary_accuracy: 0.9756 - val_loss: 0.2824 - val_binary_accuracy: 0.9048\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.1379 - binary_accuracy: 0.9756 - val_loss: 0.2822 - val_binary_accuracy: 0.9048\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1377 - binary_accuracy: 0.9756 - val_loss: 0.2821 - val_binary_accuracy: 0.9048\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1376 - binary_accuracy: 0.9756 - val_loss: 0.2819 - val_binary_accuracy: 0.9048\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1374 - binary_accuracy: 0.9756 - val_loss: 0.2817 - val_binary_accuracy: 0.9048\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1372 - binary_accuracy: 0.9756 - val_loss: 0.2817 - val_binary_accuracy: 0.9048\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1370 - binary_accuracy: 0.9756 - val_loss: 0.2816 - val_binary_accuracy: 0.9048\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1368 - binary_accuracy: 0.9756 - val_loss: 0.2815 - val_binary_accuracy: 0.9048\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1367 - binary_accuracy: 0.9756 - val_loss: 0.2814 - val_binary_accuracy: 0.9048\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1365 - binary_accuracy: 0.9756 - val_loss: 0.2814 - val_binary_accuracy: 0.9048\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1363 - binary_accuracy: 0.9756 - val_loss: 0.2812 - val_binary_accuracy: 0.9048\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1361 - binary_accuracy: 0.9756 - val_loss: 0.2811 - val_binary_accuracy: 0.9048\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1359 - binary_accuracy: 0.9756 - val_loss: 0.2809 - val_binary_accuracy: 0.9048\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1358 - binary_accuracy: 0.9756 - val_loss: 0.2808 - val_binary_accuracy: 0.9048\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1356 - binary_accuracy: 0.9756 - val_loss: 0.2808 - val_binary_accuracy: 0.9048\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1354 - binary_accuracy: 0.9756 - val_loss: 0.2807 - val_binary_accuracy: 0.9048\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1352 - binary_accuracy: 0.9756 - val_loss: 0.2806 - val_binary_accuracy: 0.9048\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1351 - binary_accuracy: 0.9756 - val_loss: 0.2804 - val_binary_accuracy: 0.9048\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1349 - binary_accuracy: 0.9756 - val_loss: 0.2805 - val_binary_accuracy: 0.9048\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1347 - binary_accuracy: 0.9756 - val_loss: 0.2804 - val_binary_accuracy: 0.9048\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1346 - binary_accuracy: 0.9756 - val_loss: 0.2803 - val_binary_accuracy: 0.9048\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1344 - binary_accuracy: 0.9756 - val_loss: 0.2803 - val_binary_accuracy: 0.9048\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1342 - binary_accuracy: 0.9756 - val_loss: 0.2802 - val_binary_accuracy: 0.9048\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1340 - binary_accuracy: 0.9756 - val_loss: 0.2803 - val_binary_accuracy: 0.9048\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1339 - binary_accuracy: 0.9756 - val_loss: 0.2802 - val_binary_accuracy: 0.9048\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1337 - binary_accuracy: 0.9756 - val_loss: 0.2801 - val_binary_accuracy: 0.9048\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1335 - binary_accuracy: 0.9756 - val_loss: 0.2801 - val_binary_accuracy: 0.9048\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1334 - binary_accuracy: 0.9756 - val_loss: 0.2800 - val_binary_accuracy: 0.9048\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1332 - binary_accuracy: 0.9756 - val_loss: 0.2800 - val_binary_accuracy: 0.9048\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1330 - binary_accuracy: 0.9756 - val_loss: 0.2799 - val_binary_accuracy: 0.9048\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1329 - binary_accuracy: 0.9756 - val_loss: 0.2799 - val_binary_accuracy: 0.9048\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1327 - binary_accuracy: 0.9756 - val_loss: 0.2798 - val_binary_accuracy: 0.9048\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1325 - binary_accuracy: 0.9756 - val_loss: 0.2797 - val_binary_accuracy: 0.9048\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1324 - binary_accuracy: 0.9756 - val_loss: 0.2796 - val_binary_accuracy: 0.9048\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1322 - binary_accuracy: 0.9756 - val_loss: 0.2797 - val_binary_accuracy: 0.9048\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1320 - binary_accuracy: 0.9756 - val_loss: 0.2796 - val_binary_accuracy: 0.9048\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1319 - binary_accuracy: 0.9756 - val_loss: 0.2794 - val_binary_accuracy: 0.9048\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1317 - binary_accuracy: 0.9756 - val_loss: 0.2794 - val_binary_accuracy: 0.9048\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1315 - binary_accuracy: 0.9756 - val_loss: 0.2794 - val_binary_accuracy: 0.9048\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1314 - binary_accuracy: 0.9756 - val_loss: 0.2793 - val_binary_accuracy: 0.9048\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1312 - binary_accuracy: 0.9756 - val_loss: 0.2793 - val_binary_accuracy: 0.8952\n"
          ]
        }
      ],
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=20,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    batch_size=512,\n",
        "    epochs=1000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, # hide the output because we have so many epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbc00fd4",
      "metadata": {
        "papermill": {
          "duration": 0.01018,
          "end_time": "2021-11-09T00:11:17.697387",
          "exception": false,
          "start_time": "2021-11-09T00:11:17.687207",
          "status": "completed"
        },
        "tags": [],
        "id": "bbc00fd4"
      },
      "source": [
        "我們將一如既往地查看學習曲線，並檢查我們在驗證集上獲得的損失和準確性的最佳值。 （請記住，提前停止會將權重恢復為獲得這些值的權重。）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7a8c4a6d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-09T00:11:17.725478Z",
          "iopub.status.busy": "2021-11-09T00:11:17.724747Z",
          "iopub.status.idle": "2021-11-09T00:11:18.274438Z",
          "shell.execute_reply": "2021-11-09T00:11:18.273724Z"
        },
        "papermill": {
          "duration": 0.567085,
          "end_time": "2021-11-09T00:11:18.274597",
          "exception": false,
          "start_time": "2021-11-09T00:11:17.707512",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "7a8c4a6d",
        "outputId": "01e8d853-dbbf-4d1a-f129-79ca612a6c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation Loss: 0.2793\n",
            "Best Validation Accuracy: 0.9143\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1d348c83k5UkhJAECAQIyI4IaFgUUdQiKootiKCiUAW1LLUubWn1cffRx/qzaot9RIu7VQQX8EGtCG4FhSCyK/uSRQiEhOzbnN8fd5JMkkkyCTOZZOb7fr3mNXPvPWfmO8PwzZlzzz1HjDEopZTyX0G+DkAppZR3aaJXSik/p4leKaX8nCZ6pZTyc5rolVLKzwX7OoDa4uPjTXJysq/DUEqpNmXTpk3HjTEJro61ukSfnJxMamqqr8NQSqk2RUQO1XdMu26UUsrPaaJXSik/p4leKaX8XKvro3elrKyMtLQ0iouLfR2KaqXCw8NJSkoiJCTE16Eo1eq0iUSflpZGdHQ0ycnJiIivw1GtjDGGEydOkJaWRq9evXwdjlKtTpvouikuLiYuLk6TvHJJRIiLi9NffErVo00kekCTvGqQfj+Uql+b6LpRSrUMu93wyrqD5BSW+jqUgNQlJoLrR/Xw+PNqoldKVdn18yke/mgnAPojqeUN695BE70vHTx4kCuvvJLt27fX2D979mzuuusuBg0a5KPIlPKc9JNFAKyYP4azkjr4OBrlKZroT9NLL73kkecpLy8nOLh1/nNUVFRgs9l8HYZqARk5VqLv2iHCx5EoT2qdmaUBD63cwc6MUx59zkFd2/PAVYMbLVdeXs4NN9zA999/z+DBg3nttde44ooreOqpp0hJSSEqKoo77riDjz76iIiICD788EM6d+7MypUrefTRRyktLSUuLo4333yTzp078+CDD7Jv3z72799Pjx49SE9P57nnnmPYsGEAnH/++SxatIihQ4fWiWXDhg3ccccdFBcXExERwcsvv0z//v2pqKjgj3/8I5988glBQUHMmTOHBQsWsHHjRu644w4KCgoICwvj888/Z/ny5aSmpvL3v/8dgCuvvJJ77rmHcePGERUVxW233cbq1atZtGgRa9asYeXKlRQVFXHeeefxwgsvICLs3buX22+/naysLGw2G++++y4PPfQQkydP5pe//CUAN9xwA9deey1XX321B//VlDdk5BYTGhxEXGSor0NRHtRmRt20Bj/99BNz585l165dtG/fnueff77G8YKCAkaPHs2WLVu44IILePHFFwErYX/77bds3ryZ6dOn8+STT1bV2blzJ6tXr+Zf//oXt9xyC6+88goAu3fvpri42GWSBxgwYABff/01mzdv5uGHH+bPf/4zAIsXL+bgwYP88MMPbN26lRtuuIHS0lKmTZvGs88+y5YtW1i9ejUREQ232AoKChg1ahRbtmzh/PPPZ/78+WzcuJHt27dTVFTERx99BFhJfN68eWzZsoV169aRmJhY433k5uaybt06Jk6c2OTPW7W8jJwiusaE6ygmP9PmWvTutLy9pXv37owZMwaAGTNm8Nxzz9U4HhoaypVXXgnAOeecw2effQZYF3xNmzaNzMxMSktLa1zUM2nSpKqkO3XqVB555BH+8pe/sGTJEmbNmlVvLLm5ucycOZM9e/YgIpSVlQGwevVqbr/99qpuoI4dO7Jt2zYSExMZMWIEAO3bt2/0vdpsNqZMmVK1vXbtWp588kkKCwvJzs5m8ODBjBs3jvT0dH71q18B1tWpABdeeCFz584lKyuL5cuXM2XKlFbbLaXg2/0n+OPyrWTkFBEkwtk9Yn0dkvIwbdE3Qe1WTu3tkJCQqn02m43y8nIAFixYwPz589m2bRsvvPBCjQt7IiMjqx63a9eO8ePH8+GHH7J06VJuuOGGemP5r//6Ly666CK2b9/OypUrm3WxUHBwMHa7vWrb+TnCw8Or+uWLi4uZO3cuy5YtY9u2bcyZM6fR17vpppt44403ePnll7n55pubHJtqOZ9s/5lDJwopqzCc0zOWWy/o7euQlIdpom+Cw4cPs379egDeeustzj//fLfq5ebm0q1bNwBeffXVBsvOnj2b3/72t4wYMYLY2PpbVs7PWdlNAjB+/HheeOGFqj8y2dnZ9O/fn8zMTDZu3AhAXl4e5eXlJCcn88MPP2C32zly5AgbNmxw+VqVST0+Pp78/HyWLVsGQHR0NElJSXzwwQcAlJSUUFhYCMCsWbN45plnAHREko8Ul1W4dcsuqB4zf+/EgVw0oJMPo1beoL+nm6B///4sWrSIm2++mUGDBvGb3/yGlStXNlrvwQcfZOrUqcTGxnLxxRdz4MCBesuec845tG/fnl//+tcNPucf/vAHZs6cyaOPPlqj/3v27Nns3r2bs846i5CQEObMmcP8+fN55513WLBgAUVFRURERLB69WrGjBlDr169GDRoEAMHDuTss892+VodOnRgzpw5nHnmmXTp0qWqCwjg9ddf57bbbuP+++8nJCSEd999l969e9O5c2cGDhxYdUJWtayn//0Tz63Z2+R63XS0jV8SY4yvY6ghJSXF1F5hateuXQwcONBHEbWsjIwMxo0bx48//khQUNv9wVVYWMiQIUP4/vvviYmJaZHXDKTvSWNmvPQdB08UcMOonm6Vjwyz0aFdKJOGdvVyZMpbRGSTMSbF1TFt0bcir732Gvfeey9PP/10m07yq1ev5pZbbuHOO+9ssSTvj3KLyjhwvKBZdQ+eKGBoUgd+M+4MD0el2iJN9K3ITTfdxE033VRj38svv8yzzz5bY9+YMWNYtGhRS4bWJL/4xS84dKje5SuVm+a9+T3f7D3e7PraOleVNNG3cr/+9a8b7a9X/mlfVj5j+8Zz85imz7EvAiOSO3ohKtUWaaJXyseKyyr4eHsmpeXVQ12NgaOnipl6TpKOglGnTRO9Uj72f1szufvdLS6PDUhs/OI2pRrjVqIXkcuAZwEb8JIx5olax3sCS4AEIBuYYYxJcxyrALY5ih42xkzyUOxK+YXD2YWIwFe/vwhbUPVFeME2oVN0uA8jU/6i0UQvIjZgETAeSAM2isgKY8xOp2JPAa8ZY14VkYuBx4EbHceKjDHDPBy3Uq3Svqx83vruMPYmDFtev+8EnaLD6N6xnRcjU4HMnRb9SGCvMWY/gIi8DVwNOCf6QcBdjsdrgQ88GWRbFBUVRX5+vstjX3zxBU899VTVxGDOrrjiCt566y06dNC5wNuiN749xMv/OUh0eNN6Ra84M9FLESnlXqLvBhxx2k4DRtUqswWYjNW98ysgWkTijDEngHARSQXKgSeMMXX+CIjIrcCtAD16eH51lbZk1apVHnme1jq/vTEGY0ybvk6gIekni+jXOYp/33mhr0NRqoqnMsE9wN9FZBbwFZAOVDiO9TTGpItIb2CNiGwzxuxzrmyMWQwsBuvK2AZf6eOF8PO2Bos0WZchcPkTDRZZuHAh3bt3Z968eYA1rUFwcDBr167l5MmTlJWV8eijj7o95/qpU6eYOHEie/fu5aKLLuL5558nKCiI5ORkUlNTyc/P5/LLL+f8889n3bp1dOvWjQ8//JCIiAhefPFFFi9eTGlpKX369OH111+nXbt2zJo1i/DwcDZv3syYMWNYuXIl69atIyEhAbvdTr9+/Vi/fj0JCQl14qlvzvz8/HwWLFhAamoqIsIDDzzAlClT+OSTT/jzn/9MRUUF8fHxfP755zz44INERUVxzz33AHDmmWdW/WqZMGECo0aNYtOmTaxatYonnniCjRs3UlRUxDXXXMNDDz0E4HLe/IkTJ7o9T78vvPjVftb+dAyAbem5nNNTZ39UrYs7zap0oLvTdpJjXxVjTIYxZrIxZjhwr2NfjuM+3XG/H/gCGH76Ybe8adOmsXTp0qrtpUuXMnPmTN5//32+//571q5dy9133427U0ps2LCBv/3tb+zcuZN9+/bx3nvv1SmzZ88e5s2bx44dO+jQoQPLly8HYPLkyWzcuJEtW7YwcOBA/vnPf1bVSUtLY926dTz99NPMmDGDN998E7CuVh06dKjLJA/1z5n/yCOPEBMTw7Zt29i6dSsXX3wxWVlZzJkzh+XLl7NlyxbefffdRt/vnj17mDt3Ljt27KBnz5489thjpKamsnXrVr788ku2bt1a77z5TZmn3xdeWXeQPcfyKauwM6BLNJPPTvJ1SErV4E6LfiPQV0R6YSX46cD1zgVEJB7INsbYgT9hjcBBRGKBQmNMiaPMGOBJTkcjLW9vGT58OMeOHSMjI4OsrCxiY2Pp0qULd955J1999RVBQUGkp6dz9OhRunTp0ujzjRw5kt69relgr7vuOr755huuueaaGmV69epV1Yo955xzOHjwIADbt2/nvvvuIycnh/z8fCZMmFBVZ+rUqVXTC998881cffXV/O53v2PJkiUNXnhV35z5q1ev5u23364qFxsby8qVK7nggguqynTs2PiFOT179mT06NFV20uXLmXx4sWUl5eTmZnJzp07ERGX8+Y3ZZ7+llZhN/x8qpjfXHgG90zo7+twlHKp0URvjCkXkfnAp1jDK5cYY3aIyMNAqjFmBTAOeFxEDFbXzTxH9YHACyJix/r18ESt0TptytSpU1m2bBk///wz06ZN48033yQrK4tNmzYREhJCcnKy2/PCNza3PUBYWFjVY5vNRlGRtZ7nrFmz+OCDDxg6dCivvPIKX3zxRVU55/ntu3fvTufOnVmzZg0bNmyoat27smDBAu666y4mTZrEF198wYMPPujW+3DW0Pz2znEdOHCAp556io0bNxIbG8usWbMa/Nxqz9O/adOmJsfmLDO3iGkvfEtBSflpPQ+A3Rgq7IbEDjoMUrVebvXRG2NWAatq7bvf6fEyYJmLeuuAIacZY6sxbdo05syZw/Hjx/nyyy9ZunQpnTp1IiQkhLVr1zZpfpcNGzZw4MABevbsyTvvvMOtt97qdt28vDwSExMpKyvjzTffrJqX3pXZs2czY8YMbrzxxgYX+K5vzvzx48ezaNGiqrnlT548yejRo5k7dy4HDhygV69eZGdn07FjR5KTk6v65L///vt6p2M+deoUkZGRxMTEcPToUT7++GPGjRtXY978ESNGkJeXR0REBMHBwcyePZurrrqKsWPHNjhPvzu2puVyOLuQK89KpEO7kNN6LoBQm40Jgxv/FaeUr7S+YRmt2ODBg8nLy6Nbt24kJiZyww03cNVVVzFkyBBSUlIYMGCA2881YsQI5s+fX3UytnI5Pnc88sgjjBo1ioSEBEaNGkVeXl69ZSdNmuTWfDn1zZl/3333MW/ePM4880xsNhsPPPAAkydPZvHixUyePBm73U6nTp347LPPmDJlCq+99hqDBw9m1KhR9OvXz+VrDR06lOHDhzNgwIAayzOGhoa6nDc/KirK7Xn63ZGRY/0yemjSYOKiwhoprVTbp/PR+7nU1FTuvPNOvv76a1+Hclrcmaff3e/Jf6/axavrDvLjI5fpItjKbzQ0H71/DmZWADzxxBNMmTKFxx9/3NehnJbXXnuNUaNG8dhjj3lk/H16ThHdOkRoklcBQ7tuvGjbtm3ceOONNfaFhYXx3XfftcjrL1y4kIULF9bY99hjj9UZDjl16lTuvffeFompOVzN099URaUVbD58EruBvUfz9eSpCihtJtEbY9pcC2zIkCH88MMPvg6jhnvvvbdVJ/XmaqwL8oWv9vHM6j1V2yN7ubfEnlL+oE0k+vDwcE6cOEFcXFybS/bK+4wxnDhxgvDw+lvpB48X0KV9OH+73rpeb3BXnf5XBY42keiTkpJIS0sjKyvL16EoLzPGUFhagb2eBnpocBBhwXX76cPDw0lKSmJbWi7fHTjBmD7xJESHseKHDOzGsCUtl55x7XTVJRWQ2kSiDwkJqboKU/m3dfuOc/1r9Z/D6N4xgq//cHG9x+/7YBtb0nI574w4RiR35NnPq7trxg/q7NFYlWor2kSiV4Ej7aQ1xv3jO8aSFBtR49hzn+9hyX8OUmE3NRbocHbEUT/tZBGJMUV0bh/G6rusmSSjwvTrrgKTfvNVq7AjI5dX1x1kV2YeItA7IZKw4JpX8vaMi6TCbrjznR8IddF9YwxkF5QC1kVR/9l7nKTYdkSHn/7Vr0q1ZZroVavwrw2HWbYpjcSYCCYM6lInyQOM7NWR3vGRbDp0st7n6RnXjmvOTuLdTWlU2A2XaneNUproVeuQkVPMgC7tWXXH2HrL9OsczZp7xrn1fAsu6euhyJRq+zTRK5/562e7WfOjtWDH3mP5jOkT7+OIlPJPmuiVz7y/OZ3ScjuDurYnITqM60Z2b7ySUqrJNNErn8krLuPKs7ryyC/P9HUoSvk1ndRM+YQxhrzicqLDta2hlLdpolc+UVxmp9xuiNJEr5TX6f8y1aKKyyrIyCniZKE13l3HuCvlfZroVYua/Woq3+w9XrUdFxnqw2j8yMmD8M9L4ZZ/w57P4Nt/wM2fQFSnumUPfgOvTITITnDmZNj+XvWx4DCY9jp0He7iNQ7BP8db9fKPeu2teF3BMYhMgLg+kL0f8o9Z73vS3+Csa30dnVdoolct6qejeYzpE8e1Kd0JCw7iogEuEpFqus1vWsn3h3/Bppetx8d3u070//4v677gGGx4Edp3gz6XQFkRbH0bMre4TvRb3raeN/8odBkC3VwuZtS6ZWy23ndBlnWrVF4MqUs00St1OlIPZnP0VAnH80u4YVQPrh5W/4Lm6jTZK6z70oLGy5oKSEqBq56Bohwr0btTb+AkuPAPpxenL3zzV8isZ42IVrasqidpoldel11QytQX1lf9P+rbKdq3Afkz5/UaSupfNL6G0EjHfZSjXr77ddqayvdYKaIjFGX7JpYWpIleeV12QQnGwMLLBzB+UGd6x7fRJNEWOLdKS91I2ABhjj+8tmAIDodSN/5A1E6YbUXtuKMTAyLR6/BK5XWnissB6N85mjMSonSVsJbiThcM1Ex+oVEN1HP6IxLWRhN97bijnSa9s5e3bCwtSFv0yuvyHIleL45y4ehOyE1rfv3IeCg4bp14Bcj6ESqsoatkboHd/65Z3thrnoSEmt0wYVFwfE/depXPXVWnjSb62l1O7ZzmV0pPhbRNUHjC+pykhdvBQTboOQZCPL9wvf7PU16XV1wG6Jj5Oux2ePFiKC/y3HPu/KD68dZ3rFtjohNrPj74tXVrsE6X5sXna87vFaB9IgSFgN36jvJS/auXtYjL/wKjbvX407qV6EXkMuBZwAa8ZIx5otbxnsASIAHIBmYYY9Icx2YC9zmKPmqMedVDsas2YMWWDF78aj+gLfo6KkqtJD9iDgy9run135ttjQMfPBnOnQ/BoVBeap2QbRdntfSdfXQH/LwNxvwOhlxj7TN26Dykusz0tyD7QP2vGRwKtlCI79f0eFuDTgNhfipEdYbsfdBpEIyeCxVl8EytOZdGz4Uzr2mhwAy8dAkUHm+8aDM0+j9PRGzAImA8kAZsFJEVxpidTsWeAl4zxrwqIhcDjwM3ikhH4AEgBauDb5Ojbv0rRyi/8tLX+zlwvIAL+yWQEB3m63Bal4oS675jL0g6p+n128Vbib5jb9f1Y3vW3A7vYN13GmSNg3f5nB2tmz+Ld6xVUHmtQOWvk9ComiewE/o379+luUKj3Bvx1AzudEKNBPYaY/YbY0qBt4Gra5UZBKxxPF7rdHwC8JkxJtuR3D8DLjv9sFVbkZFTxFVDE3n15pGE2PTcfw0Vju4CWzOvDg5ytNOaOtSxrQ6N9LpagwRCWvhzCo10b8RTM7jzW7obcMRpOw0YVavMFmAyVvfOr4BoEYmrp26dK2VE5FbgVoAePXq4G7tqJd787hAvfe365/7x/FISYyJcHgt45Y4Wve00z12EuXldQuVop9B2p/d6fqvWBVNBdZez9KoGRzydHk91mt4D/F1EZgFfAelAhbuVjTGLgcUAKSkp/nt5mp/6ZPvPnCoqc7lC1PAeHbhqaFcfRNUGVI6OsZ1ml5a7I2Cqxtjr8NYGhUZ7rWXdoDDvdd24k+jTAeelf5Ic+6oYYzKwWvSISBQwxRiTIyLpwLhadb84jXhVK2C3G8rs9qrt9JwiRvXuyHPXuZgfpSVk74c1j1YnTme2MOvE45a3rS6SCY/Vnf+lMBs++ROUFUBYDEx8CkI8+Cvkm2cgfZN1cq/nudX7q7pumtmir2xxaleMZwSHW330YVG+SfSh0e5f5NZE7iT6jUBfEemFleCnA9c7FxCReCDbGGMH/oQ1AgfgU+C/RSTWsX2p47hqw371/H/YkpZbY98lvpycbM9nsH05xPev+XO7ogxO7LGGClbOttj/cmvGRmeHv7XmeInqbJU7ZxZ0H+G5+L580voj0i6uVqJ3dN0EN7NFf+58azKursPcK3/FU/Dpn6HH6Oa9nr+79FH4/lWY8N/w+UPQd3zLvn58H9+16I0x5SIyHytp24AlxpgdIvIwkGqMWYHVan9cRAxW1808R91sEXkE648FwMPGGP+/3tjP7crMY3TvjoztmwBAkAhXD/Nh90zlnC63f10zaRYch7+cUXNKXVd9oJX7Lr4PVizwbKvKmOpx8rVfu6rrppknY/tfZt3c1WkA3Phe4+UC1bDrrBvATR+2/Otf9azXntqtPnpjzCpgVa199zs9XgYsq6fuEqpb+KqNKy6roLTCzti+Ccy7qI+vw7GU5lsjUGonTOcujcqhc66SeOXP9Kgu1c/nKWVF1lh1V89bXpno9UIy5V063k01SeV0Bu1b08VPJflWIq89h05wOIijKyeqc3VZV/Whejy1J38+Oyf32rNJeupkrFKN0ESvmqRVTmdQWuB6iKFI9SRW7TpaLX5XJ9kqk3HlHwNPtuidn6v2857uOHql3NSKmmXK50ryrYUo6nE8v5RPNh0hmkI6BBVBcW69ZVtUcU79QwxDo6w4Q6OsW2F23bgLs62LY8LbW9sFxxt/b0HBVtdQeQkg1tQAzkryal7paAuF4lM1n7c4x7qvXVcpD9NEryzbl8OymxssEg/MBeaGA++3RFBN0L2ekSThHeBUOoTHWLfNr1u32tp3s7p6bKHw5RPWrUECk1+E92+zfjX8fr81nzvAd4vh49/DhX+0/ogAdOgBJ/bCEy4uCAzRC5iUd2miV5bKiazGP1LvFYFvbThMXlEZM0b3JDKslX11ep7nev9Vz0LaBuh7qTU9b8Zm1+W6DLG6eqa9aQ3JbEh5MXz+MBz40voFVJwLJaeq54g5/pN1n/VT9Qnh65fC7k+pc/VlRKy1SLVSXtTK/rcqn6nsLz5vQd2Tmg6vfPslyV0juW1cG1oUuvuI6jHx8X3r/4NQqd+lWJd7NKCizEr0eT9X7ystqE70lcMoSwsAY43vjzsDzp3bnHeg1GnTk7HKUlFizcvdwOpPmTnFdO2g89ZgC7FGyuQ7J3oXo2tK8x0jgvTKVeVb2qJXloqyBq/QPFVcRl5JOV07eH71mzYpLKpmi77ExeiaknxrDH1bXXZP+Q1N9MpSXuLywp1Fa/eybt9xisusi360Re8QGgU5h6q3awyjLHDaZ2ouV6eUD2iiD2R7V0PSSGtYYUWpy/HcL369n7DgILrHtmNs33hGJvv5ohTuqj2cc/syOOZYiyfHMTN35TDNToNaNjalatFEH6hy0+GNKdB/Ilz3ltV1U+sKzcLScnIKy/jDZf2ZO05HhtSQ0A+O7bDG00sQbH6j5vFQpxkQE9rosnvKb2iiD1RlhdZ91o/WfUXNrpvsglIu/MtaALrqwiF1TVliDd0MjgCMNeTSWVj76pOylRdiKeUjmugDVVlRze1aXTe7Mk+RV1zOsO4duKi/D6cgbq2CgqwLsCq5OpGtCV61Ejq8MlC5mknRcSl+WYWdPUet1uhz04cT064VzWujlGoybdEHKldzozta9L9+eSPf7D1OcJDQOUZnVlSqrdNEH6jqTJlbVpXot2fkMrp3R34zrg9hwS28QLJSyuM00fu771+Hb5+vu7/IMXNi9j54/lxrrpseoygosUbaXNAvgQv7JbRsrEopr9BE7+9++tgaStn7grrHDpVAj3OtaQ/izoAhU8nMtU7SdtMLo5TyG5ro/V1pPnQaCNPeaLwskL47C9ArYJXyJ5ro/V1pvjUneyOMMazYksGaH48BmuiV8iea6P1dST7EJDVa7OCJQu54+wcAOkWH0TlaR9so5S800fu70gIIdbGeai1pJ60rZV+eNYIxfeIJtuklFkr5C030bcmJfdZomSCbNf2tMY3XKc6F0EiO5RXz3Od7KC23Vx1KiA5DEI7lFXPohJXo+3SKIjRYk7xS/kQTfVtxKhP+dg51lqJzR2QCq3ce441vD9O5fRhBIhSVVZBTaK0q1aFdCBEhNkYkx5IYo/PNK+VvNNG3Ffk/AwZSboHUf1r7rn+38XoSBD3PJWNtGrYgYd3CS7AFCev3neC6F78F4Pnrz+a8PjpnulL+yq1ELyKXAc8CNuAlY8wTtY73AF4FOjjKLDTGrBKRZGAX4FgtmW+NMbd7JvQAUzllQa+x1Ym+XyNrmwLvfZ/Gq4s3k3ayiC7tw7EFWUsFOo+T1xE2Svm3RhO9iNiARcB4IA3YKCIrjDE7nYrdByw1xvxDRAYBq4Bkx7F9xphhng07AFUuVRfVpUnV3t+czsEThQzv0aHGla5JsRFcN7I7xkD3ju08GalSqpVxp0U/EthrjNkPICJvA1cDzoneAJVzssYAGZ4MUlE922S7pq3wlJFTxHlnxPGPGefU2B8UJDw++SxPRaeUasXcGV7RDTjitJ3m2OfsQWCGiKRhteYXOB3rJSKbReRLERl7OsEGtMpEX3sJuwbsyMhlX1YBXfQEq1IBzVPj6K4DXjHGJAFXAK+LSBCQCfQwxgwH7gLeEpE6qzGIyK0ikioiqVlZWR4KqQ058BWs/B2seQzsdtdlKrtuwtxP9D8csSYumzC4ad09Sin/4k7XTTrQ3Wk7ybHP2S3AZQDGmPUiEg7EG2OOASWO/ZtEZB/QD0h1rmyMWQwsBkhJSWnG+ME2bt3fYM+/rcdnTYN4F+uzVg5MXE8AABYMSURBVLboQyJh0C/dWnD6+0M5BAmM0AW9lQpo7iT6jUBfEemFleCnA9fXKnMYuAR4RUQGAuFAlogkANnGmAoR6Q30BfZ7LHp/UeK02lPtlZ+c9wdHgC0Yrn210afccCCb5d+n0Sk6rGqkjVIqMDWa6I0x5SIyH/gUa+jkEmPMDhF5GEg1xqwA7gZeFJE7sU7MzjLGGBG5AHhYRMoAO3C7MSbba++mrSrNg5B21oLd9SX6kvwmddv85FgK8Mlr9ISrUoHOrXH0xphVWCdZnffd7/R4JzDGRb3lwPLTjNH/leRDdBfI3l+zde+sNL9JJ2K/3p2FLUi4oK8uHqJUoNNJTVqD0nyITqx+7EoTWvR2u+HfO4/SLsRGkHbbKBXwNNG3BqUFENXZ8fj0W/QnCkoBmHNBb09Ep5Rq43SuG1/437GQcwiCw6EwG+xlEOO4NOGjO+H/7rEeRzgWDCnKscr0nYDdbnht/UFyi8rrffrj+SUADEysM5JVKRWANNG3NHsF/LzVsZELyWOhx2g4eybE9YGTh6xDR3fAnk+tx/2vgIQBMGAiOzJO8eDKnS6f2llkqI2BiY3PQ6+U8n+a6Fta5eRklQZOglG3Wo/PmVW9f/vy6kQ/fAYMmAhA2rZMAD5acD6DGmixi4CI9s8rpTTRt7zaffChka7LOffHOx6XlFfwp/e3AdakZHqiVSnlDj0Z29JqD5+sbySNi0S/M+MUOYVldO8YQUxEiJcCVEr5G030La1Oi76eRO/8B8DxODO3GIDFN6Zot4xSym3adeNNmVusk6v9r7C2d38MR76rWaa+RO+iRf/Cl/sA6BqjC4Uopdynid6bXhoPFSUwc6W1pN87M+qWad/Vdd1IpytaHXPQZ+YWExMRQkw77bZRSrlPE703VVjj2Sk6Cbaw6v0x3eE366CiFCJrrtVaXmHHboDgKGz37KfCABIG5XaO5ZXw20v6tlj4Sin/oIneW4zTbMsl+RDm1Kce3QXC6w6N/HpPFrNe3kiFvf6ZmpN0fVelVBPpyVhvcR4vX5pvtd4ric1llS1HcqiwG+4e349fDrO6dEJsQt9OVh99RIiNy4foIiJKqabRRO8tzqNrSvJqJvp6pOcUExcZyoJL+jJjdE8AzkiIYlh3ayqE2y88g+hw7Z9XSjWNdt14S40WfQGUlzRaJSOniK6OrplEx/2YPvFVY+Z7xGm3jVKq6TTRe8u+NdWPS/Ohoqx6OzjUZZXM3CJ6xVtXynbrEMG/77yAXvGRlFcYUnrGMqKXLgmolGo67brxluO7rfugEOtkbGXXTc8xMPbuOsUPnyhk99H8qhY9QL/O0YTYgogItXFen3hCbPrPpZRqOm3Re0tJvjWMMjTK0aJ3dN3c+D4Eh9Upfv+K7QAM6KIzTiqlPEubiN5SmmdNWBYaWbPrJsj1ydQj2YWk9Izl2pTuLRikUioQaKL3ltICqzUfFmW17stLICgYgup+5NkFpezLKmBo9w46h41SyuM00XtL5RqvoVFW0q8orXl1rJNPtv8M0OD88kop1VzaR++uijI4le5++aKTENXJSvTFOdaSgTbX3TYZOUXYgoRfDu/moWCVUqqaJnp3fTAXti1tWp0eoyEs2voDseUt6+RsLcYYXvx6P13ah2PThUSUUl6gid5dOYchYSCM+a37dXqPs06+djkLMNa6r7WcLCyjpNxOt1i9GEop5R2a6N1Vmg8de8Ow65ted9h19R7KyCkC4OYxvZobmVJKNUhPxrqrJK/+Zf+aaWfGKa782zeAdSWsUkp5g1uJXkQuE5GfRGSviCx0cbyHiKwVkc0islVErnA69idHvZ9EZIIng29Rpfn1rwbVTKmHsqsed+0Q7tHnVkqpSo123YiIDVgEjAfSgI0issIYs9Op2H3AUmPMP0RkELAKSHY8ng4MBroCq0WknzGmwtNvxOtKCzzaos8rLmPfseoZLjtGup7/RimlTpc7ffQjgb3GmP0AIvI2cDXgnOgNUDkIPAbIcDy+GnjbGFMCHBCRvY7nW++B2FtO/jEoL/ZYi37ToZNM+ce6Gvv0QimllLe403XTDTjitJ3m2OfsQWCGiKRhteYXNKEuInKriKSKSGpWVpabobegH//Puo9J8sjT7cw8VWN71W/HeuR5lVLKFU+NurkOeMUY8/9E5FzgdRE5093KxpjFwGKAlJSU+tfR85XKueUHTGxW9SPZhRw5WVi1/eHmmhdeDeqqV8QqpbzHnUSfDjhf6ZPk2OfsFuAyAGPMehEJB+LdrNv6Va4WFRLZrOrXvrCezNziGvsSosPIyith4lmJpxudUko1yJ1EvxHoKyK9sJL0dKD2YPLDwCXAKyIyEAgHsoAVwFsi8jTWydi+wAYPxd5ySvIgOAJsTf8BVFRaQWZuMdeP6sGkoV2ZvvhbAJbMHEFCdBixkbo0oFLKuxrNXMaYchGZD3wK2IAlxpgdIvIwkGqMWQHcDbwoIndinZidZYwxwA4RWYp14rYcmNc2R9zkN2vETYXd8Mzn1gIkI5JjGd07rurY4K7tCdIpD5RSLcCtJqoxZhXWSVbnffc7Pd4JjKmn7mPAY6cRo++VFljzyjfRxoPZvPDlfgAGOmamvHpYVz7beVSTvFKqxegUCPX5eTu8fb01j3zRSYjv1+SnOJJtnYD9+I6xDOhiJfpnpw/3aJhKKdUYTfT1yfwBcg7BmddYrfk+v3C76q7MU7y2/lDVMMreCc07iauUUp6gib4+lUMqL38SIuMaLlvLW98d5p2Nh0mIDuMXAzsTFmzzQoBKKeUeTfT1Kcmz7pvRN5+RU0T/Lu35+A69EEop5Xs6e2V9SvOtNV6DXS//50p+STk3LdnA+v0n6KaTlCmlWglN9PWpXNy7CXPQbE/P5avdWfTvEs20ET28GJxSSrlPu26KT0HaBmv0v7Pje5o8iVnlIiJPXzuMXvF6AlYp1Tpoov/icfj2edfHuqU0Wv33725h5VZrss7yCuuvRWKMdtsopVoPTfQFWdC+G0x9te6xjr0brf7N3uMkx0VyYb8EwBpKGR6io2yUUq2HJvqSfGjXEbqPcKt4TmEpuUVlxEWFcexUMUdPFTP1nCTuurS/lwNVSqnm0URfmg+h0W4VzSsu49zH11BUVnO6nu4d23kjMqWU8ghN9CV5ENXJraKHswspKqsgNDiI0nI7I3t15MbRPRk/qLOXg1RKqebTRF85jLIBW9NyyMwtZkd6LgBDusWw6dBJRiZ35KqhXVsiSqWUarbATvTr/gYn9kCP0fUWKSgpZ/Lz6yi3WyNqQmzCxQM6senQSR1CqZRqEwI70X/xP9Z9n0vqLZKeU0S53bDw8gGM7RtPbLtQurQP5/Izu5Acp4leKdX6BW6iNwbKi+D8u2Dwr2ocKigp541vD1FSbuewY6rhEcmxDO4aU1Wmd0LTFyJRSilfCNxEX14C9nKXK0d9tvMoj3/8Y9V2h3YhnKGJXSnVRgVuoq9c8NvFidh0x1QGOx6aQHiIDQFdEUop1WZpoq8n0cdFhhIZFrgfj1LKfwTu7JUljkTvousmI6eIrh0iWjggpZTyjsBN9JvfsO7DY+ocshK9TkymlPIPgZvoK7tuepxX51BGTjGJMdqiV0r5h8BO9HF9ITi0xu5TxWXkl5TTTbtulFJ+IoATfYHL9WCPOMbNax+9UspfBG6iL8mHsJqzVm5Pz2Xic98A0C1WE71Syj8EbqIvzasztHJrmjVp2W0X9uasbnVP0iqlVFvkVqIXkctE5CcR2SsiC10c/6uI/OC47RaRHKdjFU7HVngy+GY5tB6+/QecyqzRdVNSXsHnu44iAr+/tL9eIKWU8huNXhEkIjZgETAeSAM2isgKY8zOyjLGmDudyi8Ahjs9RZExZpjnQj5N798GOYesx/H9qnb/9//t4vMfj5Ec145gW+D+0FFK+R93Lv0cCew1xuwHEJG3gauBnfWUvw54wDPheUFxLpw9E8Y/XGMM/d6sfERgySz3lhRUSqm2wp2mazfgiNN2mmNfHSLSE+gFrHHaHS4iqSLyrYj8sp56tzrKpGZlZbkZejMYYw2rbBcHER1ArO6Z8go7/9l7giuGJOqslEopv+PpPorpwDJjjPOiqj2NMSnA9cAzInJG7UrGmMXGmBRjTEpCQoKHQ3JSz4yV/9l3AoCEqDDvvbZSSvmIO4k+HejutJ3k2OfKdOBfzjuMMemO+/3AF9Tsv29ZVROZ1RxWWTnn/O0X1vkbpJRSbZ47ffQbgb4i0gsrwU/Hap3XICIDgFhgvdO+WKDQGFMiIvHAGOBJTwTeLCV51n1oJMVlFfzvl/soKbfzz28OYAsSOkVri14p5X8aTfTGmHIRmQ98CtiAJcaYHSLyMJBqjKkcMjkdeNsYY5yqDwReEBE71q+HJ5xH67SofWvgM8c54rAovjuQzTOr91Qdvqh/gg6pVEr5JbcmXDfGrAJW1dp3f63tB13UWwcMOY34POd1p+UCQ6PIyC6q2jwjIZKXfz3SB0EppZT3BeaA8bBoMnKqE31EqM2HwSillHcF5hJKoZFk5BQTagtiZK+OzDwv2dcRKaWU1wRooo8iIyeTs5JieGP2KF9Ho5RSXhW4XTe5RSTqVMRKqQAQmIk+NJLsglLiIkMbL6uUUm1cYCT6k4dqbNqDQskvKad9eGD2XCmlAktgJPr8owC8UX4J+6/9jN5/XoUxEKWJXikVAAIj0zmuiH2/4nwyDrcHrInTosNDfBiUUkq1jIBo0efmnASgkHC2pedW7Y/WFr1SKgAERKL/59rtAOQTztd7jlftb68teqVUAPD7RG+MoSDPWtnwrzeez7/mjK46lhgT7quwlFKqxfh930VuURlhFYUQBCl9e0BIdXLXcfRKqUDg9y369JwiIqUIu9gg2JqGeJZjyoOoML//O6eUUv6f6DNzimlHCfaQyKqlAx+cNJiDT0z0cWRKKdUy/CbR5xSWcu/725j96kaO5RVX7c/ILSKKIiQsuoHaSinlv/wm0Qfbgnjzu8Os3nWMu5duqdqflVdClBQTFK6JXikVmPwm0Tv3t2fllVQ9zisup72tBAmNclVNKaX8nt8kemc//pyH3W6taHiquIxoKYHQSB9HpZRSvuFXif5/plSvWniysBSAfsc/5yzzI2gfvVIqQPlVop82ogdPTjkLgKKyCgC6FP5oHRx7t6/CUkopn/KrRA8Q7lj/tdiR6G1lBeQHRUO3s30ZllJK+YzfJfqIECvRF5XaAQgpL6Q0qJ0vQ1JKKZ/y30TvaNGHVBRQFqyJXikVuPwv0Ydab6morAJjDGH2IsqDdcSNUipw+U+iLyuCre/SvsCxbODJg5TuXsv5Qdus6Q+UUipA+c+sXqWF8N5sYsc+CvTmwo9/UXWoOLKr7+JSSikfc6tFLyKXichPIrJXRBa6OP5XEfnBcdstIjlOx2aKyB7HbaYng6/BcUFUmCmssXuzvQ+HRj/qtZdVSqnWrtEWvYjYgEXAeCAN2CgiK4wxOyvLGGPudCq/ABjueNwReABIAQywyVH3pEffBVhTEAcFE2mKsQVJ1e6d9p5cP7ibx19OKaXaCnda9COBvcaY/caYUuBt4OoGyl8H/MvxeALwmTEm25HcPwMuO52A6yUCoVEEleXTpX314iIVIZGISAMVlVLKv7mT6LsBR5y20xz76hCRnkAvYE1T6orIrSKSKiKpWVlZ7sTtWlg0lBaQFBNWtatCT8QqpQKcp0fdTAeWGWMqmlLJGLPYGJNijElJSEho/quHRkJJHj3bV+/SETdKqUDnzqibdKC703aSY58r04F5teqOq1X3C/fDa6LQKDj4NQuCD1XtkhC9WEopFdjcadFvBPqKSC8RCcVK5itqFxKRAUAssN5p96fApSISKyKxwKWOfd4xdDokDCA6LJg8E0Gaiaf9wEu89nJKKdUWNNqiN8aUi8h8rARtA5YYY3aIyMNAqjGmMulPB942xhinutki8gjWHwuAh40x2Z59C05GzoGRc4gxhl5/WgXAwQnjvPZySinVFrh1wZQxZhWwqta++2ttP1hP3SXAkmbG1yw6ykYppar5z5WxtTx33XAiHVMWK6VUIPPbRD9pqE57oJRS4E+TmimllHJJE71SSvk5TfRKKeXnNNErpZSf00SvlFJ+ThO9Ukr5OU30Sinl5zTRK6WUnxOnqWlaBRHJAg41WrCueOC4h8Npi/RzsOjnoJ9BpUD5HHoaY1zO897qEn1ziUiqMSbF13H4mn4OFv0c9DOopJ+Ddt0opZTf00SvlFJ+zp8S/WJfB9BK6Odg0c9BP4NKAf85+E0fvVJKKdf8qUWvlFLKBU30Sinl5/wi0YvIZSLyk4jsFZGFvo7HW0Sku4isFZGdIrJDRO5w7O8oIp+JyB7Hfaxjv4jIc47PZauInO3bd+BZImITkc0i8pFju5eIfOd4v+84FrNHRMIc23sdx5N9GbcniUgHEVkmIj+KyC4ROTcQvw8icqfj/8R2EfmXiIQH4vehPm0+0YuIDVgEXA4MAq4TkUG+jcpryoG7jTGDgNHAPMd7XQh8bozpC3zu2AbrM+nruN0K/KPlQ/aqO4BdTtv/A/zVGNMHOAnc4th/C3DSsf+vjnL+4lngE2PMAGAo1ucRUN8HEekG/BZIMcacCdiA6QTm98E1Y0ybvgHnAp86bf8J+JOv42qh9/4hMB74CUh07EsEfnI8fgG4zql8Vbm2fgOSsJLYxcBHgGBd/Rhc+3sBfAqc63gc7Cgnvn4PHvgMYoADtd9LoH0fgG7AEaCj49/3I2BCoH0fGrq1+RY91f/IldIc+/ya4+fmcOA7oLMxJtNx6Gegs+OxP382zwB/AOyO7TggxxhT7th2fq9Vn4PjeK6jfFvXC8gCXnZ0Yb0kIpEE2PfBGJMOPAUcBjKx/n03EXjfh3r5Q6IPOCISBSwHfmeMOeV8zFjNFL8eMysiVwLHjDGbfB2LjwUDZwP/MMYMBwqo7qYBAub7EAtcjfWHrysQCVzm06BaGX9I9OlAd6ftJMc+vyQiIVhJ/k1jzHuO3UdFJNFxPBE45tjvr5/NGGCSiBwE3sbqvnkW6CAiwY4yzu+16nNwHI8BTrRkwF6SBqQZY75zbC/DSvyB9n34BXDAGJNljCkD3sP6jgTa96Fe/pDoNwJ9HWfYQ7FOwqzwcUxeISIC/BPYZYx52unQCmCm4/FMrL77yv03OUZbjAZynX7St1nGmD8ZY5KMMclY/95rjDE3AGuBaxzFan8OlZ/PNY7ybb6Va4z5GTgiIv0duy4BdhJg3wesLpvRItLO8X+k8nMIqO9Dg3x9ksATN+AKYDewD7jX1/F48X2ej/UzfCvwg+N2BVb/4ufAHmA10NFRXrBGJO0DtmGNSvD5+/DwZzIO+MjxuDewAdgLvAuEOfaHO7b3Oo739nXcHnz/w4BUx3fiAyA2EL8PwEPAj8B24HUgLBC/D/XddAoEpZTyc/7QdaOUUqoBmuiVUsrPaaJXSik/p4leKaX8nCZ6pZTyc5rolVLKz2miV0opP/f/ARhQgfK4gyAnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "# Start the plot at epoch 5\n",
        "history_df.loc[5:, ['loss', 'val_loss']].plot()\n",
        "history_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n",
        "\n",
        "print((\"Best Validation Loss: {:0.4f}\" +\\\n",
        "      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n",
        "      .format(history_df['val_loss'].min(), \n",
        "              history_df['val_binary_accuracy'].max()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0435de",
      "metadata": {
        "papermill": {
          "duration": 0.015474,
          "end_time": "2021-11-09T00:11:18.303643",
          "exception": false,
          "start_time": "2021-11-09T00:11:18.288169",
          "status": "completed"
        },
        "tags": [],
        "id": "dd0435de"
      },
      "source": [
        "# EXERCISE\n",
        "\n",
        "使用神經網絡 [**預測酒店預訂中的取消**](https://www.kaggle.com/kernels/fork/11887335) 和 *Hotel Cancellations* 數據集。"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "formats": "ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 23.691106,
      "end_time": "2021-11-09T00:11:21.762676",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-11-09T00:10:58.071570",
      "version": "2.3.3"
    },
    "colab": {
      "name": "Intro to Deep Learning - L6 - binary-classification.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}